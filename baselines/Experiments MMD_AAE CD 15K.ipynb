{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C19qic_Hygck","executionInfo":{"status":"ok","timestamp":1696186251760,"user_tz":240,"elapsed":17205,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"4d582c44-83a1-4eca-f80b-40e67c22587c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bXUyIi4x3gMY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186251761,"user_tz":240,"elapsed":9,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"df436556-8d9f-4a24-9d69-2521b56467d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Shareddrives/Anomaly\n"]}],"source":["%cd /content/gdrive/Shareddrives/Anomaly/"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5ED6MSGv4AvS","executionInfo":{"status":"ok","timestamp":1696186258975,"user_tz":240,"elapsed":7218,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.utils import resample\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","#from autoencoder import Autoencoder\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data.dataset import Dataset as dataset\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ldNOyaS_LfPF","executionInfo":{"status":"ok","timestamp":1696186262394,"user_tz":240,"elapsed":3422,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["train_df = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/TRAIN_FINAL_CROSS_DOM_15K.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RQFh9FVxrwW7","colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"status":"ok","timestamp":1696186262395,"user_tz":240,"elapsed":17,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"6d165d68-5604-4bbd-9cf6-0814426580a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","0        -0.632694        -0.580092         -0.881051        -0.598698   \n","1        -0.712442         1.429695         -0.374214        -0.852608   \n","2        -0.632694        -0.580092         -0.881051        -0.598698   \n","3        -0.512219         0.741109         -0.261913        -0.598698   \n","4         1.709488        -0.580092          1.686548         1.800385   \n","\n","   Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","0        -0.686276        -0.635757         -0.698694        -0.588015   \n","1        -0.536097         3.273131          0.201001        -0.794297   \n","2        -0.686276        -0.635757         -0.698694        -0.588015   \n","3        -0.468995         1.592125         -0.091600        -0.588015   \n","4         1.352691        -0.635757         -0.000646         0.862475   \n","\n","   Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","0    -0.085003     0.369437  ...    -0.694505    -0.517268     -0.835366   \n","1    -0.068330    -0.136598  ...    -0.490374    -0.598422      0.082195   \n","2    -0.085003    -0.164555  ...    -0.694505    -0.517268     -0.835366   \n","3    -0.081888    -0.163937  ...    -0.416409    -0.490281     -0.084858   \n","4    -0.084752    -0.164529  ...     0.844407     0.309143      0.273510   \n","\n","   Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  Init Bwd Win Byts  \\\n","0         -0.881051         -0.698694           0.130146          -0.314942   \n","1         -0.374214          0.201001          -0.755270          -0.426041   \n","2         -0.881051         -0.698694          -0.468538          -0.314942   \n","3         -0.261913         -0.091600          -0.468538          -0.314942   \n","4          1.686548         -0.000646           0.481678           4.010477   \n","\n","   Fwd Seg Size Min  Idle Min  Label  \n","0          0.680731 -0.344192    0.0  \n","1         -1.445423 -0.361189    0.0  \n","2         -2.426335  1.906829    0.0  \n","3         -1.183509 -0.344192    0.0  \n","4          0.680731 -0.344192    0.0  \n","\n","[5 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-9e244893-773d-4bcb-94e5-ec7ef996ff04\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>0.369437</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>0.130146</td>\n","      <td>-0.314942</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.712442</td>\n","      <td>1.429695</td>\n","      <td>-0.374214</td>\n","      <td>-0.852608</td>\n","      <td>-0.536097</td>\n","      <td>3.273131</td>\n","      <td>0.201001</td>\n","      <td>-0.794297</td>\n","      <td>-0.068330</td>\n","      <td>-0.136598</td>\n","      <td>...</td>\n","      <td>-0.490374</td>\n","      <td>-0.598422</td>\n","      <td>0.082195</td>\n","      <td>-0.374214</td>\n","      <td>0.201001</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>-0.164555</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-2.426335</td>\n","      <td>1.906829</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.512219</td>\n","      <td>0.741109</td>\n","      <td>-0.261913</td>\n","      <td>-0.598698</td>\n","      <td>-0.468995</td>\n","      <td>1.592125</td>\n","      <td>-0.091600</td>\n","      <td>-0.588015</td>\n","      <td>-0.081888</td>\n","      <td>-0.163937</td>\n","      <td>...</td>\n","      <td>-0.416409</td>\n","      <td>-0.490281</td>\n","      <td>-0.084858</td>\n","      <td>-0.261913</td>\n","      <td>-0.091600</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.709488</td>\n","      <td>-0.580092</td>\n","      <td>1.686548</td>\n","      <td>1.800385</td>\n","      <td>1.352691</td>\n","      <td>-0.635757</td>\n","      <td>-0.000646</td>\n","      <td>0.862475</td>\n","      <td>-0.084752</td>\n","      <td>-0.164529</td>\n","      <td>...</td>\n","      <td>0.844407</td>\n","      <td>0.309143</td>\n","      <td>0.273510</td>\n","      <td>1.686548</td>\n","      <td>-0.000646</td>\n","      <td>0.481678</td>\n","      <td>4.010477</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e244893-773d-4bcb-94e5-ec7ef996ff04')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9e244893-773d-4bcb-94e5-ec7ef996ff04 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9e244893-773d-4bcb-94e5-ec7ef996ff04');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-06bb5d39-0233-4cc6-b4e7-3f758831ccc1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06bb5d39-0233-4cc6-b4e7-3f758831ccc1')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-06bb5d39-0233-4cc6-b4e7-3f758831ccc1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nVdPhpISA3uC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262395,"user_tz":240,"elapsed":12,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"e83708ea-88a1-4f15-da06-9b37a640b5be"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1.])"]},"metadata":{},"execution_count":6}],"source":["train_df['Label'].unique()"]},{"cell_type":"code","source":["train_df['Label'][train_df['Label']>1.0] = 1.0"],"metadata":{"id":"dtAuHTAYUqZS","executionInfo":{"status":"ok","timestamp":1696186262395,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yns7nxwlIY8t","executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":221,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"d5c921a1-7adc-480f-cf31-1829ff42a4a1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(156903, 30)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["train_df['Label'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9RQSy_kUvv2","executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":10,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"296947af-431f-44c5-d566-9e1a7462fb30"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1.])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df0 = train_df.iloc[0:5000]\n","#df3.loc[ df3['Label'] == 2.0, 'Label'] = 1.0\n","df0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"PQvYPs0TIino","executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"bac01fcd-9d8d-4759-892c-375ec534ba7b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","0           -0.632694        -0.580092         -0.881051        -0.598698   \n","1           -0.712442         1.429695         -0.374214        -0.852608   \n","2           -0.632694        -0.580092         -0.881051        -0.598698   \n","3           -0.512219         0.741109         -0.261913        -0.598698   \n","4            1.709488        -0.580092          1.686548         1.800385   \n","...               ...              ...               ...              ...   \n","4995         0.543304        -0.387445          0.502623         0.976004   \n","4996        -0.859313        -0.387445         -1.006168        -0.852608   \n","4997        -0.859313        -0.387445         -1.006168        -0.852608   \n","4998         1.709488        -0.580092          1.686548         1.800385   \n","4999         0.646113        -0.387445          0.613215         1.110038   \n","\n","      Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","0           -0.686276        -0.635757         -0.698694        -0.588015   \n","1           -0.536097         3.273131          0.201001        -0.794297   \n","2           -0.686276        -0.635757         -0.698694        -0.588015   \n","3           -0.468995         1.592125         -0.091600        -0.588015   \n","4            1.352691        -0.635757         -0.000646         0.862475   \n","...               ...              ...               ...              ...   \n","4995         0.392243        -0.434899          0.191880         0.604133   \n","4996        -0.849295        -0.434899         -0.814463        -0.794297   \n","4997        -0.849295        -0.434899         -0.814463        -0.794297   \n","4998         1.352691        -0.635757          0.069158         0.926859   \n","4999         0.392243        -0.434899          0.191880         0.604133   \n","\n","      Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","0       -0.085003     0.369437  ...    -0.694505    -0.517268     -0.835366   \n","1       -0.068330    -0.136598  ...    -0.490374    -0.598422      0.082195   \n","2       -0.085003    -0.164555  ...    -0.694505    -0.517268     -0.835366   \n","3       -0.081888    -0.163937  ...    -0.416409    -0.490281     -0.084858   \n","4       -0.084752    -0.164529  ...     0.844407     0.309143      0.273510   \n","...           ...          ...  ...          ...          ...           ...   \n","4995    -0.068841    -0.136674  ...     0.528341     0.085442      0.244466   \n","4996    -0.068872     0.491397  ...    -0.904707    -0.660804     -1.001200   \n","4997    -0.068872     0.308209  ...    -0.904707    -0.660804     -1.001200   \n","4998    -0.084932    -0.164550  ...     0.877041     0.344565      0.335115   \n","4999    -0.068840    -0.136674  ...     0.552269     0.110570      0.277874   \n","\n","      Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","0            -0.881051         -0.698694           0.130146   \n","1            -0.374214          0.201001          -0.755270   \n","2            -0.881051         -0.698694          -0.468538   \n","3            -0.261913         -0.091600          -0.468538   \n","4             1.686548         -0.000646           0.481678   \n","...                ...               ...                ...   \n","4995          0.502623          0.191880           1.339820   \n","4996         -1.006168         -0.814463          -0.745451   \n","4997         -1.006168         -0.814463          -0.737268   \n","4998          1.686548          0.069158           0.481678   \n","4999          0.613215          0.191880           1.339820   \n","\n","      Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","0             -0.314942          0.680731 -0.344192    0.0  \n","1             -0.426041         -1.445423 -0.361189    0.0  \n","2             -0.314942         -2.426335  1.906829    0.0  \n","3             -0.314942         -1.183509 -0.344192    0.0  \n","4              4.010477          0.680731 -0.344192    0.0  \n","...                 ...               ...       ...    ...  \n","4995          -0.415745          1.105003  0.012011    1.0  \n","4996          -0.414014         -0.170210 -0.361189    0.0  \n","4997          -0.393469         -0.170210 -0.361189    0.0  \n","4998           4.010477          0.680731 -0.344192    0.0  \n","4999          -0.415745          1.105003  0.011155    1.0  \n","\n","[5000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-1adf710f-0f90-4d2e-a129-20217be09ceb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>0.369437</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>0.130146</td>\n","      <td>-0.314942</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.712442</td>\n","      <td>1.429695</td>\n","      <td>-0.374214</td>\n","      <td>-0.852608</td>\n","      <td>-0.536097</td>\n","      <td>3.273131</td>\n","      <td>0.201001</td>\n","      <td>-0.794297</td>\n","      <td>-0.068330</td>\n","      <td>-0.136598</td>\n","      <td>...</td>\n","      <td>-0.490374</td>\n","      <td>-0.598422</td>\n","      <td>0.082195</td>\n","      <td>-0.374214</td>\n","      <td>0.201001</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>-0.164555</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-2.426335</td>\n","      <td>1.906829</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.512219</td>\n","      <td>0.741109</td>\n","      <td>-0.261913</td>\n","      <td>-0.598698</td>\n","      <td>-0.468995</td>\n","      <td>1.592125</td>\n","      <td>-0.091600</td>\n","      <td>-0.588015</td>\n","      <td>-0.081888</td>\n","      <td>-0.163937</td>\n","      <td>...</td>\n","      <td>-0.416409</td>\n","      <td>-0.490281</td>\n","      <td>-0.084858</td>\n","      <td>-0.261913</td>\n","      <td>-0.091600</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.709488</td>\n","      <td>-0.580092</td>\n","      <td>1.686548</td>\n","      <td>1.800385</td>\n","      <td>1.352691</td>\n","      <td>-0.635757</td>\n","      <td>-0.000646</td>\n","      <td>0.862475</td>\n","      <td>-0.084752</td>\n","      <td>-0.164529</td>\n","      <td>...</td>\n","      <td>0.844407</td>\n","      <td>0.309143</td>\n","      <td>0.273510</td>\n","      <td>1.686548</td>\n","      <td>-0.000646</td>\n","      <td>0.481678</td>\n","      <td>4.010477</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>0.543304</td>\n","      <td>-0.387445</td>\n","      <td>0.502623</td>\n","      <td>0.976004</td>\n","      <td>0.392243</td>\n","      <td>-0.434899</td>\n","      <td>0.191880</td>\n","      <td>0.604133</td>\n","      <td>-0.068841</td>\n","      <td>-0.136674</td>\n","      <td>...</td>\n","      <td>0.528341</td>\n","      <td>0.085442</td>\n","      <td>0.244466</td>\n","      <td>0.502623</td>\n","      <td>0.191880</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>0.012011</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>0.491397</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.745451</td>\n","      <td>-0.414014</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>0.308209</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737268</td>\n","      <td>-0.393469</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>1.709488</td>\n","      <td>-0.580092</td>\n","      <td>1.686548</td>\n","      <td>1.800385</td>\n","      <td>1.352691</td>\n","      <td>-0.635757</td>\n","      <td>0.069158</td>\n","      <td>0.926859</td>\n","      <td>-0.084932</td>\n","      <td>-0.164550</td>\n","      <td>...</td>\n","      <td>0.877041</td>\n","      <td>0.344565</td>\n","      <td>0.335115</td>\n","      <td>1.686548</td>\n","      <td>0.069158</td>\n","      <td>0.481678</td>\n","      <td>4.010477</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>0.646113</td>\n","      <td>-0.387445</td>\n","      <td>0.613215</td>\n","      <td>1.110038</td>\n","      <td>0.392243</td>\n","      <td>-0.434899</td>\n","      <td>0.191880</td>\n","      <td>0.604133</td>\n","      <td>-0.068840</td>\n","      <td>-0.136674</td>\n","      <td>...</td>\n","      <td>0.552269</td>\n","      <td>0.110570</td>\n","      <td>0.277874</td>\n","      <td>0.613215</td>\n","      <td>0.191880</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>0.011155</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1adf710f-0f90-4d2e-a129-20217be09ceb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1adf710f-0f90-4d2e-a129-20217be09ceb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1adf710f-0f90-4d2e-a129-20217be09ceb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bd94e3b2-7e0b-43ea-87db-c1801bd49a6f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd94e3b2-7e0b-43ea-87db-c1801bd49a6f')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bd94e3b2-7e0b-43ea-87db-c1801bd49a6f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df1 = train_df.iloc[5000:10000]\n","#df3.loc[ df3['Label'] == 2.0, 'Label'] = 1.0\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"3sCAx0FpIfKG","executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"96ed8548-b4df-4b37-fcde-ba8827a484f9"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","5000        -0.522849        -0.580092         -0.692882        -0.405823   \n","5001        -0.859313        -0.387445         -1.006168        -0.852608   \n","5002         1.567728        -0.387445          1.221471         1.278762   \n","5003        -0.859313        -0.387445         -1.006168        -0.852608   \n","5004        -0.859313        -0.387445         -1.006168        -0.852608   \n","...               ...              ...               ...              ...   \n","9995         1.038993        -0.387445         -0.470762         0.308837   \n","9996        -0.859313        -0.387445         -1.006168        -0.852608   \n","9997        -0.730801         1.202553         -0.453208        -0.852608   \n","9998        -0.135974        -0.387445         -0.280636        -0.192502   \n","9999         1.615482        -0.431168          0.789558         0.982524   \n","\n","      Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","5000        -0.686276        -0.635757         -0.698694        -0.588015   \n","5001        -0.849295        -0.434899         -0.814463        -0.794297   \n","5002         1.350590        -0.434899          0.146883         0.759315   \n","5003        -0.849295        -0.434899         -0.814463        -0.794297   \n","5004        -0.849295        -0.434899         -0.814463        -0.794297   \n","...               ...              ...               ...              ...   \n","9995        -0.371059        -0.434899         -0.676973        -0.506425   \n","9996        -0.849295        -0.434899         -0.814463        -0.794297   \n","9997        -0.731143         0.963939         -0.431384        -0.794297   \n","9998         1.832577        -0.434899          0.784188         1.246842   \n","9999         1.300719        -0.433878          0.254808         0.844208   \n","\n","      Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","5000    -0.055843    -0.119892  ...    -0.612462    -0.514919     -0.755001   \n","5001    -0.068872     0.231504  ...    -0.904707    -0.660804     -1.001200   \n","5002    -0.068537    -0.136644  ...     0.863768     0.475667      0.435372   \n","5003    -0.068872    -0.136672  ...    -0.904707    -0.660804     -1.001200   \n","5004    -0.068872    -0.131368  ...    -0.904707    -0.660804     -1.001200   \n","...           ...          ...  ...          ...          ...           ...   \n","9995    -0.068869    -0.136676  ...    -0.333528    -0.542253     -0.731544   \n","9996    -0.068872    -0.136672  ...    -0.904707    -0.660804     -1.001200   \n","9997    -0.011585    -0.118941  ...    -0.808416    -0.657435     -0.366436   \n","9998    -0.068861    -0.136676  ...     1.090164     0.785269      0.386452   \n","9999    -0.058596    -0.485225  ...     0.730360     0.089731      0.315075   \n","\n","      Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","5000         -0.692882         -0.698694          -0.438500   \n","5001         -1.006168         -0.814463          -0.734930   \n","5002          1.221471          0.146883          -0.116783   \n","5003         -1.006168         -0.814463          -0.737969   \n","5004         -1.006168         -0.814463          -0.735320   \n","...                ...               ...                ...   \n","9995         -0.470762         -0.676973          -0.116783   \n","9996         -1.006168         -0.814463           1.339820   \n","9997         -0.453208         -0.431384          -0.755270   \n","9998         -0.280636          0.784188          -0.116783   \n","9999          0.789558          0.254808           1.264288   \n","\n","      Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","5000          -0.314942          0.680731 -0.344192    0.0  \n","5001          -0.426041         -0.170210 -0.361189    0.0  \n","5002           2.516327         -0.170210 -0.361189    0.0  \n","5003          -0.426041          1.105003 -0.361189    1.0  \n","5004          -0.426041         -0.170210 -0.361189    0.0  \n","...                 ...               ...       ...    ...  \n","9995          -0.377417         -0.170210 -0.071241    0.0  \n","9996          -0.426041          1.955144 -0.361189    1.0  \n","9997          -0.426041         -1.445423 -0.361189    0.0  \n","9998          -0.417757         -0.170210  2.747098    0.0  \n","9999          -0.326173          0.786912 -0.117185    1.0  \n","\n","[5000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-2c834e8d-8126-4850-a2be-bc2419bb6b4b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5000</th>\n","      <td>-0.522849</td>\n","      <td>-0.580092</td>\n","      <td>-0.692882</td>\n","      <td>-0.405823</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.055843</td>\n","      <td>-0.119892</td>\n","      <td>...</td>\n","      <td>-0.612462</td>\n","      <td>-0.514919</td>\n","      <td>-0.755001</td>\n","      <td>-0.692882</td>\n","      <td>-0.698694</td>\n","      <td>-0.438500</td>\n","      <td>-0.314942</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5001</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>0.231504</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.734930</td>\n","      <td>-0.426041</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5002</th>\n","      <td>1.567728</td>\n","      <td>-0.387445</td>\n","      <td>1.221471</td>\n","      <td>1.278762</td>\n","      <td>1.350590</td>\n","      <td>-0.434899</td>\n","      <td>0.146883</td>\n","      <td>0.759315</td>\n","      <td>-0.068537</td>\n","      <td>-0.136644</td>\n","      <td>...</td>\n","      <td>0.863768</td>\n","      <td>0.475667</td>\n","      <td>0.435372</td>\n","      <td>1.221471</td>\n","      <td>0.146883</td>\n","      <td>-0.116783</td>\n","      <td>2.516327</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5003</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136672</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737969</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5004</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.131368</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.735320</td>\n","      <td>-0.426041</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>1.038993</td>\n","      <td>-0.387445</td>\n","      <td>-0.470762</td>\n","      <td>0.308837</td>\n","      <td>-0.371059</td>\n","      <td>-0.434899</td>\n","      <td>-0.676973</td>\n","      <td>-0.506425</td>\n","      <td>-0.068869</td>\n","      <td>-0.136676</td>\n","      <td>...</td>\n","      <td>-0.333528</td>\n","      <td>-0.542253</td>\n","      <td>-0.731544</td>\n","      <td>-0.470762</td>\n","      <td>-0.676973</td>\n","      <td>-0.116783</td>\n","      <td>-0.377417</td>\n","      <td>-0.170210</td>\n","      <td>-0.071241</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136672</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>1.339820</td>\n","      <td>-0.426041</td>\n","      <td>1.955144</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>-0.730801</td>\n","      <td>1.202553</td>\n","      <td>-0.453208</td>\n","      <td>-0.852608</td>\n","      <td>-0.731143</td>\n","      <td>0.963939</td>\n","      <td>-0.431384</td>\n","      <td>-0.794297</td>\n","      <td>-0.011585</td>\n","      <td>-0.118941</td>\n","      <td>...</td>\n","      <td>-0.808416</td>\n","      <td>-0.657435</td>\n","      <td>-0.366436</td>\n","      <td>-0.453208</td>\n","      <td>-0.431384</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>-0.135974</td>\n","      <td>-0.387445</td>\n","      <td>-0.280636</td>\n","      <td>-0.192502</td>\n","      <td>1.832577</td>\n","      <td>-0.434899</td>\n","      <td>0.784188</td>\n","      <td>1.246842</td>\n","      <td>-0.068861</td>\n","      <td>-0.136676</td>\n","      <td>...</td>\n","      <td>1.090164</td>\n","      <td>0.785269</td>\n","      <td>0.386452</td>\n","      <td>-0.280636</td>\n","      <td>0.784188</td>\n","      <td>-0.116783</td>\n","      <td>-0.417757</td>\n","      <td>-0.170210</td>\n","      <td>2.747098</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>1.615482</td>\n","      <td>-0.431168</td>\n","      <td>0.789558</td>\n","      <td>0.982524</td>\n","      <td>1.300719</td>\n","      <td>-0.433878</td>\n","      <td>0.254808</td>\n","      <td>0.844208</td>\n","      <td>-0.058596</td>\n","      <td>-0.485225</td>\n","      <td>...</td>\n","      <td>0.730360</td>\n","      <td>0.089731</td>\n","      <td>0.315075</td>\n","      <td>0.789558</td>\n","      <td>0.254808</td>\n","      <td>1.264288</td>\n","      <td>-0.326173</td>\n","      <td>0.786912</td>\n","      <td>-0.117185</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c834e8d-8126-4850-a2be-bc2419bb6b4b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2c834e8d-8126-4850-a2be-bc2419bb6b4b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2c834e8d-8126-4850-a2be-bc2419bb6b4b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4ab95176-457e-494e-b4f3-b03677b13a3b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ab95176-457e-494e-b4f3-b03677b13a3b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4ab95176-457e-494e-b4f3-b03677b13a3b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["df2 = train_df.iloc[10000:15000]\n","#df3.loc[ df3['Label'] == 2.0, 'Label'] = 1.0\n","df2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"g21boO-mIcdF","executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":7,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"77ceb565-c01f-4476-e7f1-32d7a5ade4fa"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","10000        -0.480328         1.090839         -0.098024        -0.598698   \n","10001        -0.859313        -0.387445         -1.006168        -0.852608   \n","10002        -0.859313        -0.387445         -1.006168        -0.852608   \n","10003        -0.498045         0.896544         -0.189074        -0.598698   \n","10004        -0.734473         1.157124         -0.469007        -0.852608   \n","...                ...              ...               ...              ...   \n","14995         1.031649        -0.387445          0.621115         1.352401   \n","14996        -0.498045         0.896544         -0.189074        -0.598698   \n","14997         0.068897        -0.580092          0.229754         0.336029   \n","14998        -0.829939        -0.024017         -0.879778        -0.852608   \n","14999        -0.469698        -0.580092         -0.413663        -0.345892   \n","\n","       Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","10000        -0.514189         1.128725         -0.217876        -0.588015   \n","10001        -0.849295        -0.434899         -0.814463        -0.794297   \n","10002        -0.849295        -0.434899         -0.814463        -0.794297   \n","10003        -0.571552         0.540565         -0.378149        -0.588015   \n","10004        -0.612990         2.362776         -0.048305        -0.794297   \n","...                ...              ...               ...              ...   \n","14995         0.392243        -0.434899          0.527328         0.820471   \n","14996        -0.592411         0.326688         -0.436430        -0.588015   \n","14997         1.851568        -0.635757          1.963501         2.133486   \n","14998        -0.849295        -0.434899         -0.814463        -0.794297   \n","14999        -0.686276        -0.635757         -0.698694        -0.588015   \n","\n","       Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","10000    -0.082135    -0.163918  ...    -0.523369    -0.507048     -0.115968   \n","10001    -0.068872    -0.136589  ...    -0.904707    -0.660804     -1.001200   \n","10002    -0.068872    -0.136676  ...    -0.904707    -0.660804     -1.001200   \n","10003    -0.056737    -0.155954  ...    -0.608937    -0.514713     -0.283179   \n","10004    -0.065872    -0.136109  ...    -0.604560    -0.628068     -0.156438   \n","...            ...          ...  ...          ...          ...           ...   \n","14995    -0.068779    -0.136668  ...     0.656431     0.224807      0.403157   \n","14996    -0.006621    -0.137588  ...    -0.645609    -0.516433     -0.329843   \n","14997    -0.071373    -0.163770  ...     1.845359     1.733803      1.296581   \n","14998    -0.068872    -0.136677  ...    -0.878607    -0.660556     -0.943928   \n","14999    -0.009190    -0.117807  ...    -0.579722    -0.512670     -0.516497   \n","\n","       Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","10000         -0.098024         -0.217876          -0.468538   \n","10001         -1.006168         -0.814463          -0.116783   \n","10002         -1.006168         -0.814463          -0.116783   \n","10003         -0.189074         -0.378149          -0.468538   \n","10004         -0.469007         -0.048305          -0.755270   \n","...                 ...               ...                ...   \n","14995          0.621115          0.527328           1.339820   \n","14996         -0.189074         -0.436430          -0.468538   \n","14997          0.229754          1.963501           0.481678   \n","14998         -0.879778         -0.814463          -0.738749   \n","14999         -0.413663         -0.698694          -0.438500   \n","\n","       Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","10000          -0.314942         -1.183509 -0.344192    0.0  \n","10001          -0.042620         -0.170210 -0.361189    0.0  \n","10002          -0.425994          0.679932 -0.041523    0.0  \n","10003          -0.314942         -1.183509 -0.344192    0.0  \n","10004          -0.426041         -1.445423 -0.361189    0.0  \n","...                  ...               ...       ...    ...  \n","14995          -0.415745          1.105003 -0.361189    1.0  \n","14996          -0.314942         -1.183509 -0.344192    0.0  \n","14997          -0.306687          0.680731 -0.344192    0.0  \n","14998          -0.415745          1.105003  5.267809    1.0  \n","14999          -0.314942          0.680731 -0.344192    0.0  \n","\n","[5000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-3ab57663-d965-463b-9101-54cdae01826f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10000</th>\n","      <td>-0.480328</td>\n","      <td>1.090839</td>\n","      <td>-0.098024</td>\n","      <td>-0.598698</td>\n","      <td>-0.514189</td>\n","      <td>1.128725</td>\n","      <td>-0.217876</td>\n","      <td>-0.588015</td>\n","      <td>-0.082135</td>\n","      <td>-0.163918</td>\n","      <td>...</td>\n","      <td>-0.523369</td>\n","      <td>-0.507048</td>\n","      <td>-0.115968</td>\n","      <td>-0.098024</td>\n","      <td>-0.217876</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10001</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136589</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.116783</td>\n","      <td>-0.042620</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10002</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136676</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.116783</td>\n","      <td>-0.425994</td>\n","      <td>0.679932</td>\n","      <td>-0.041523</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10003</th>\n","      <td>-0.498045</td>\n","      <td>0.896544</td>\n","      <td>-0.189074</td>\n","      <td>-0.598698</td>\n","      <td>-0.571552</td>\n","      <td>0.540565</td>\n","      <td>-0.378149</td>\n","      <td>-0.588015</td>\n","      <td>-0.056737</td>\n","      <td>-0.155954</td>\n","      <td>...</td>\n","      <td>-0.608937</td>\n","      <td>-0.514713</td>\n","      <td>-0.283179</td>\n","      <td>-0.189074</td>\n","      <td>-0.378149</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10004</th>\n","      <td>-0.734473</td>\n","      <td>1.157124</td>\n","      <td>-0.469007</td>\n","      <td>-0.852608</td>\n","      <td>-0.612990</td>\n","      <td>2.362776</td>\n","      <td>-0.048305</td>\n","      <td>-0.794297</td>\n","      <td>-0.065872</td>\n","      <td>-0.136109</td>\n","      <td>...</td>\n","      <td>-0.604560</td>\n","      <td>-0.628068</td>\n","      <td>-0.156438</td>\n","      <td>-0.469007</td>\n","      <td>-0.048305</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14995</th>\n","      <td>1.031649</td>\n","      <td>-0.387445</td>\n","      <td>0.621115</td>\n","      <td>1.352401</td>\n","      <td>0.392243</td>\n","      <td>-0.434899</td>\n","      <td>0.527328</td>\n","      <td>0.820471</td>\n","      <td>-0.068779</td>\n","      <td>-0.136668</td>\n","      <td>...</td>\n","      <td>0.656431</td>\n","      <td>0.224807</td>\n","      <td>0.403157</td>\n","      <td>0.621115</td>\n","      <td>0.527328</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>14996</th>\n","      <td>-0.498045</td>\n","      <td>0.896544</td>\n","      <td>-0.189074</td>\n","      <td>-0.598698</td>\n","      <td>-0.592411</td>\n","      <td>0.326688</td>\n","      <td>-0.436430</td>\n","      <td>-0.588015</td>\n","      <td>-0.006621</td>\n","      <td>-0.137588</td>\n","      <td>...</td>\n","      <td>-0.645609</td>\n","      <td>-0.516433</td>\n","      <td>-0.329843</td>\n","      <td>-0.189074</td>\n","      <td>-0.436430</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14997</th>\n","      <td>0.068897</td>\n","      <td>-0.580092</td>\n","      <td>0.229754</td>\n","      <td>0.336029</td>\n","      <td>1.851568</td>\n","      <td>-0.635757</td>\n","      <td>1.963501</td>\n","      <td>2.133486</td>\n","      <td>-0.071373</td>\n","      <td>-0.163770</td>\n","      <td>...</td>\n","      <td>1.845359</td>\n","      <td>1.733803</td>\n","      <td>1.296581</td>\n","      <td>0.229754</td>\n","      <td>1.963501</td>\n","      <td>0.481678</td>\n","      <td>-0.306687</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14998</th>\n","      <td>-0.829939</td>\n","      <td>-0.024017</td>\n","      <td>-0.879778</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136677</td>\n","      <td>...</td>\n","      <td>-0.878607</td>\n","      <td>-0.660556</td>\n","      <td>-0.943928</td>\n","      <td>-0.879778</td>\n","      <td>-0.814463</td>\n","      <td>-0.738749</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>5.267809</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>14999</th>\n","      <td>-0.469698</td>\n","      <td>-0.580092</td>\n","      <td>-0.413663</td>\n","      <td>-0.345892</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.009190</td>\n","      <td>-0.117807</td>\n","      <td>...</td>\n","      <td>-0.579722</td>\n","      <td>-0.512670</td>\n","      <td>-0.516497</td>\n","      <td>-0.413663</td>\n","      <td>-0.698694</td>\n","      <td>-0.438500</td>\n","      <td>-0.314942</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ab57663-d965-463b-9101-54cdae01826f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3ab57663-d965-463b-9101-54cdae01826f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3ab57663-d965-463b-9101-54cdae01826f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-413d8e8d-b5b6-48a6-8df2-0df6dc64509c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-413d8e8d-b5b6-48a6-8df2-0df6dc64509c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-413d8e8d-b5b6-48a6-8df2-0df6dc64509c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3XC3dhueEjoZ","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":6,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"c1df6eca-34d8-4bac-dc21-804635345e23"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","15000        -0.501589         0.857686         -0.207284        -0.598698   \n","15001        -0.859313        -0.387445         -1.006168        -0.852608   \n","15002        -0.345265        -0.387445          0.172427        -0.179720   \n","15003        -0.519306         0.663391         -0.298333        -0.598698   \n","15004         0.972901        -0.387445          0.964740         1.536076   \n","...                ...              ...               ...              ...   \n","19995         1.709488        -0.580092          1.686548         1.800385   \n","19996         0.748923        -0.387445          0.377812         1.022720   \n","19997        -0.763847         0.793696         -0.595398        -0.852608   \n","19998         0.293623        -0.387445          0.234042         0.650492   \n","19999         1.615482        -0.431168          0.913960         1.025935   \n","\n","       Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","15000        -0.517666         1.093079         -0.227589        -0.588015   \n","15001        -0.849295        -0.434899         -0.814463        -0.794297   \n","15002        -0.599862        -0.434899         -0.552996        -0.529172   \n","15003        -0.463780         1.645594         -0.077030        -0.588015   \n","15004         0.973628        -0.434899          0.663128         1.258987   \n","...                ...              ...               ...              ...   \n","19995         1.352691        -0.635757          0.398238         1.183784   \n","19996         0.973628        -0.434899          1.155658         1.576631   \n","19997        -0.646748         1.963108         -0.157756        -0.794297   \n","19998         0.392243        -0.434899          0.191880         0.604133   \n","19999         1.300719        -0.433878          0.178194         0.789788   \n","\n","       Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","15000    -0.033315    -0.152347  ...    -0.511145    -0.505536     -0.170408   \n","15001    -0.068872    -0.136672  ...    -0.904707    -0.660804     -1.001200   \n","15002    -0.068378    -0.136554  ...    -0.522316    -0.607670     -0.423177   \n","15003     0.032009    -0.141407  ...    -0.401129    -0.487233     -0.088747   \n","15004    -0.068828    -0.136674  ...     1.151507     0.875570      0.753948   \n","...            ...          ...  ...          ...          ...           ...   \n","19995    -0.084596    -0.164521  ...     0.987292     0.469728      0.569211   \n","19996    -0.066163    -0.136444  ...     1.110517     0.814928      0.681164   \n","19997    -0.067800    -0.136435  ...    -0.637185    -0.634798     -0.299618   \n","19998    -0.068805    -0.136669  ...     0.477834     0.033767      0.163330   \n","19999    -0.058754    -0.485233  ...     0.730339     0.089720      0.311618   \n","\n","       Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","15000         -0.207284         -0.227589          -0.468538   \n","15001         -1.006168         -0.814463          -0.737969   \n","15002          0.172427         -0.552996          -0.116783   \n","15003         -0.298333         -0.077030          -0.468538   \n","15004          0.964740          0.663128           1.339820   \n","...                 ...               ...                ...   \n","19995          1.686548          0.398238           0.481678   \n","19996          0.377812          1.155658           1.339820   \n","19997         -0.595398         -0.157756          -0.755270   \n","19998          0.234042          0.191880           1.339820   \n","19999          0.913960          0.178194           1.264288   \n","\n","       Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","15000          -0.314942         -1.183509 -0.344192    0.0  \n","15001          -0.426041          1.105003 -0.361189    1.0  \n","15002          -0.425994         -0.170210 -0.361189    0.0  \n","15003          -0.314942         -1.183509 -0.344192    0.0  \n","15004          -0.415745          1.105003  0.002953    1.0  \n","...                  ...               ...       ...    ...  \n","19995           4.010477          0.680731 -0.344192    0.0  \n","19996          -0.415745          1.105003 -0.361189    1.0  \n","19997          -0.426041         -1.445423 -0.361189    0.0  \n","19998          -0.415745          1.105003 -0.361189    1.0  \n","19999          -0.326173          0.786912 -0.117185    1.0  \n","\n","[5000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-64d50044-dc33-4da6-87c0-84371ad4c87e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15000</th>\n","      <td>-0.501589</td>\n","      <td>0.857686</td>\n","      <td>-0.207284</td>\n","      <td>-0.598698</td>\n","      <td>-0.517666</td>\n","      <td>1.093079</td>\n","      <td>-0.227589</td>\n","      <td>-0.588015</td>\n","      <td>-0.033315</td>\n","      <td>-0.152347</td>\n","      <td>...</td>\n","      <td>-0.511145</td>\n","      <td>-0.505536</td>\n","      <td>-0.170408</td>\n","      <td>-0.207284</td>\n","      <td>-0.227589</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>15001</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136672</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737969</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>15002</th>\n","      <td>-0.345265</td>\n","      <td>-0.387445</td>\n","      <td>0.172427</td>\n","      <td>-0.179720</td>\n","      <td>-0.599862</td>\n","      <td>-0.434899</td>\n","      <td>-0.552996</td>\n","      <td>-0.529172</td>\n","      <td>-0.068378</td>\n","      <td>-0.136554</td>\n","      <td>...</td>\n","      <td>-0.522316</td>\n","      <td>-0.607670</td>\n","      <td>-0.423177</td>\n","      <td>0.172427</td>\n","      <td>-0.552996</td>\n","      <td>-0.116783</td>\n","      <td>-0.425994</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>15003</th>\n","      <td>-0.519306</td>\n","      <td>0.663391</td>\n","      <td>-0.298333</td>\n","      <td>-0.598698</td>\n","      <td>-0.463780</td>\n","      <td>1.645594</td>\n","      <td>-0.077030</td>\n","      <td>-0.588015</td>\n","      <td>0.032009</td>\n","      <td>-0.141407</td>\n","      <td>...</td>\n","      <td>-0.401129</td>\n","      <td>-0.487233</td>\n","      <td>-0.088747</td>\n","      <td>-0.298333</td>\n","      <td>-0.077030</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>15004</th>\n","      <td>0.972901</td>\n","      <td>-0.387445</td>\n","      <td>0.964740</td>\n","      <td>1.536076</td>\n","      <td>0.973628</td>\n","      <td>-0.434899</td>\n","      <td>0.663128</td>\n","      <td>1.258987</td>\n","      <td>-0.068828</td>\n","      <td>-0.136674</td>\n","      <td>...</td>\n","      <td>1.151507</td>\n","      <td>0.875570</td>\n","      <td>0.753948</td>\n","      <td>0.964740</td>\n","      <td>0.663128</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>0.002953</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19995</th>\n","      <td>1.709488</td>\n","      <td>-0.580092</td>\n","      <td>1.686548</td>\n","      <td>1.800385</td>\n","      <td>1.352691</td>\n","      <td>-0.635757</td>\n","      <td>0.398238</td>\n","      <td>1.183784</td>\n","      <td>-0.084596</td>\n","      <td>-0.164521</td>\n","      <td>...</td>\n","      <td>0.987292</td>\n","      <td>0.469728</td>\n","      <td>0.569211</td>\n","      <td>1.686548</td>\n","      <td>0.398238</td>\n","      <td>0.481678</td>\n","      <td>4.010477</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>0.748923</td>\n","      <td>-0.387445</td>\n","      <td>0.377812</td>\n","      <td>1.022720</td>\n","      <td>0.973628</td>\n","      <td>-0.434899</td>\n","      <td>1.155658</td>\n","      <td>1.576631</td>\n","      <td>-0.066163</td>\n","      <td>-0.136444</td>\n","      <td>...</td>\n","      <td>1.110517</td>\n","      <td>0.814928</td>\n","      <td>0.681164</td>\n","      <td>0.377812</td>\n","      <td>1.155658</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>-0.763847</td>\n","      <td>0.793696</td>\n","      <td>-0.595398</td>\n","      <td>-0.852608</td>\n","      <td>-0.646748</td>\n","      <td>1.963108</td>\n","      <td>-0.157756</td>\n","      <td>-0.794297</td>\n","      <td>-0.067800</td>\n","      <td>-0.136435</td>\n","      <td>...</td>\n","      <td>-0.637185</td>\n","      <td>-0.634798</td>\n","      <td>-0.299618</td>\n","      <td>-0.595398</td>\n","      <td>-0.157756</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>0.293623</td>\n","      <td>-0.387445</td>\n","      <td>0.234042</td>\n","      <td>0.650492</td>\n","      <td>0.392243</td>\n","      <td>-0.434899</td>\n","      <td>0.191880</td>\n","      <td>0.604133</td>\n","      <td>-0.068805</td>\n","      <td>-0.136669</td>\n","      <td>...</td>\n","      <td>0.477834</td>\n","      <td>0.033767</td>\n","      <td>0.163330</td>\n","      <td>0.234042</td>\n","      <td>0.191880</td>\n","      <td>1.339820</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>1.615482</td>\n","      <td>-0.431168</td>\n","      <td>0.913960</td>\n","      <td>1.025935</td>\n","      <td>1.300719</td>\n","      <td>-0.433878</td>\n","      <td>0.178194</td>\n","      <td>0.789788</td>\n","      <td>-0.058754</td>\n","      <td>-0.485233</td>\n","      <td>...</td>\n","      <td>0.730339</td>\n","      <td>0.089720</td>\n","      <td>0.311618</td>\n","      <td>0.913960</td>\n","      <td>0.178194</td>\n","      <td>1.264288</td>\n","      <td>-0.326173</td>\n","      <td>0.786912</td>\n","      <td>-0.117185</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64d50044-dc33-4da6-87c0-84371ad4c87e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-64d50044-dc33-4da6-87c0-84371ad4c87e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-64d50044-dc33-4da6-87c0-84371ad4c87e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-248e456f-2fde-45be-85bb-405105f71dec\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-248e456f-2fde-45be-85bb-405105f71dec')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-248e456f-2fde-45be-85bb-405105f71dec button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":13}],"source":["df3 = train_df.iloc[15000:20000]\n","#df3.loc[ df3['Label'] == 2.0, 'Label'] = 1.0\n","df3"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_pC2lBo3EnOn","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1696186262609,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"fb0ec8f1-e25d-4ad6-b97e-3d057baf2fdd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","20000         1.626477        -0.387445          0.801222         1.156921   \n","20001         0.925168        -0.387445          0.182696         0.620703   \n","20002        -0.829939        -0.024017         -0.879778        -0.852608   \n","20003        -0.345265        -0.387445          0.172427        -0.179720   \n","20004        -0.738145         1.111696         -0.484806        -0.852608   \n","...                ...              ...               ...              ...   \n","24995        -0.859313        -0.387445         -1.006168        -0.852608   \n","24996        -0.859313        -0.387445         -1.006168        -0.852608   \n","24997        -0.345265        -0.387445          0.172427        -0.179720   \n","24998         0.047637        -0.580092         -0.161759         0.152257   \n","24999        -0.572915         3.155978          0.226143        -0.852608   \n","\n","       Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","20000         1.350590        -0.434899          1.278791         1.403824   \n","20001         1.888840        -0.434899          1.499974         1.533088   \n","20002        -0.849295        -0.434899         -0.814463        -0.794297   \n","20003        -0.599862        -0.434899         -0.552996        -0.529172   \n","20004        -0.637371         2.074127         -0.127353        -0.794297   \n","...                ...              ...               ...              ...   \n","24995        -0.849295        -0.434899         -0.814463        -0.794297   \n","24996        -0.849295        -0.434899         -0.814463        -0.794297   \n","24997        -0.599862        -0.434899         -0.552996        -0.529172   \n","24998         1.851568        -0.635757          2.840908         2.244565   \n","24999        -0.552976         3.073297          0.146275        -0.794297   \n","\n","       Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","20000    -0.068432    -0.136647  ...     1.346243     1.180359      1.065894   \n","20001    -0.068829    -0.136675  ...     1.609992     1.637104      1.174539   \n","20002    -0.068872    -0.136677  ...    -0.878607    -0.660556     -0.943928   \n","20003    -0.068543    -0.136595  ...    -0.522316    -0.607670     -0.423177   \n","20004    -0.025660    -0.127697  ...    -0.629591    -0.633300     -0.146893   \n","...            ...          ...  ...          ...          ...           ...   \n","24995    -0.068872    -0.136672  ...    -0.904707    -0.660804     -1.001200   \n","24996    -0.068872    -0.136676  ...    -0.904707    -0.660804     -1.001200   \n","24997    -0.068601    -0.136610  ...    -0.522316    -0.607670     -0.423177   \n","24998    -0.084813    -0.164547  ...     2.041468     2.094844      1.533713   \n","24999     0.218498    -0.099732  ...    -0.629591    -0.633300      0.497417   \n","\n","       Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","20000          0.801222          1.278791          -0.116783   \n","20001          0.182696          1.499974          -0.116783   \n","20002         -0.879778         -0.814463          -0.738749   \n","20003          0.172427         -0.552996          -0.116783   \n","20004         -0.484806         -0.127353          -0.755270   \n","...                 ...               ...                ...   \n","24995         -1.006168         -0.814463          -0.737969   \n","24996         -1.006168         -0.814463          -0.737580   \n","24997          0.172427         -0.552996          -0.116783   \n","24998         -0.161759          2.840908           0.481678   \n","24999          0.226143          0.146275          -0.755270   \n","\n","       Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","20000           2.515579         -0.170210 -0.361189    0.0  \n","20001           1.079049         -0.170210  0.172356    0.0  \n","20002          -0.415745          1.105003  5.267714    1.0  \n","20003          -0.425994         -0.170210 -0.361189    0.0  \n","20004          -0.426041         -1.445423 -0.361189    0.0  \n","...                  ...               ...       ...    ...  \n","24995          -0.426041          1.105003 -0.361189    1.0  \n","24996          -0.426041          1.105003  0.117167    1.0  \n","24997          -0.425994         -0.170210 -0.361189    0.0  \n","24998          -0.244289          0.680731 -0.344192    0.0  \n","24999          -0.426041         -1.445423 -0.361189    0.0  \n","\n","[5000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-da1ac56c-ef82-44b3-b424-3f926f78ff2a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20000</th>\n","      <td>1.626477</td>\n","      <td>-0.387445</td>\n","      <td>0.801222</td>\n","      <td>1.156921</td>\n","      <td>1.350590</td>\n","      <td>-0.434899</td>\n","      <td>1.278791</td>\n","      <td>1.403824</td>\n","      <td>-0.068432</td>\n","      <td>-0.136647</td>\n","      <td>...</td>\n","      <td>1.346243</td>\n","      <td>1.180359</td>\n","      <td>1.065894</td>\n","      <td>0.801222</td>\n","      <td>1.278791</td>\n","      <td>-0.116783</td>\n","      <td>2.515579</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20001</th>\n","      <td>0.925168</td>\n","      <td>-0.387445</td>\n","      <td>0.182696</td>\n","      <td>0.620703</td>\n","      <td>1.888840</td>\n","      <td>-0.434899</td>\n","      <td>1.499974</td>\n","      <td>1.533088</td>\n","      <td>-0.068829</td>\n","      <td>-0.136675</td>\n","      <td>...</td>\n","      <td>1.609992</td>\n","      <td>1.637104</td>\n","      <td>1.174539</td>\n","      <td>0.182696</td>\n","      <td>1.499974</td>\n","      <td>-0.116783</td>\n","      <td>1.079049</td>\n","      <td>-0.170210</td>\n","      <td>0.172356</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20002</th>\n","      <td>-0.829939</td>\n","      <td>-0.024017</td>\n","      <td>-0.879778</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136677</td>\n","      <td>...</td>\n","      <td>-0.878607</td>\n","      <td>-0.660556</td>\n","      <td>-0.943928</td>\n","      <td>-0.879778</td>\n","      <td>-0.814463</td>\n","      <td>-0.738749</td>\n","      <td>-0.415745</td>\n","      <td>1.105003</td>\n","      <td>5.267714</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20003</th>\n","      <td>-0.345265</td>\n","      <td>-0.387445</td>\n","      <td>0.172427</td>\n","      <td>-0.179720</td>\n","      <td>-0.599862</td>\n","      <td>-0.434899</td>\n","      <td>-0.552996</td>\n","      <td>-0.529172</td>\n","      <td>-0.068543</td>\n","      <td>-0.136595</td>\n","      <td>...</td>\n","      <td>-0.522316</td>\n","      <td>-0.607670</td>\n","      <td>-0.423177</td>\n","      <td>0.172427</td>\n","      <td>-0.552996</td>\n","      <td>-0.116783</td>\n","      <td>-0.425994</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20004</th>\n","      <td>-0.738145</td>\n","      <td>1.111696</td>\n","      <td>-0.484806</td>\n","      <td>-0.852608</td>\n","      <td>-0.637371</td>\n","      <td>2.074127</td>\n","      <td>-0.127353</td>\n","      <td>-0.794297</td>\n","      <td>-0.025660</td>\n","      <td>-0.127697</td>\n","      <td>...</td>\n","      <td>-0.629591</td>\n","      <td>-0.633300</td>\n","      <td>-0.146893</td>\n","      <td>-0.484806</td>\n","      <td>-0.127353</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136672</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737969</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136676</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737580</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>0.117167</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>-0.345265</td>\n","      <td>-0.387445</td>\n","      <td>0.172427</td>\n","      <td>-0.179720</td>\n","      <td>-0.599862</td>\n","      <td>-0.434899</td>\n","      <td>-0.552996</td>\n","      <td>-0.529172</td>\n","      <td>-0.068601</td>\n","      <td>-0.136610</td>\n","      <td>...</td>\n","      <td>-0.522316</td>\n","      <td>-0.607670</td>\n","      <td>-0.423177</td>\n","      <td>0.172427</td>\n","      <td>-0.552996</td>\n","      <td>-0.116783</td>\n","      <td>-0.425994</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>0.047637</td>\n","      <td>-0.580092</td>\n","      <td>-0.161759</td>\n","      <td>0.152257</td>\n","      <td>1.851568</td>\n","      <td>-0.635757</td>\n","      <td>2.840908</td>\n","      <td>2.244565</td>\n","      <td>-0.084813</td>\n","      <td>-0.164547</td>\n","      <td>...</td>\n","      <td>2.041468</td>\n","      <td>2.094844</td>\n","      <td>1.533713</td>\n","      <td>-0.161759</td>\n","      <td>2.840908</td>\n","      <td>0.481678</td>\n","      <td>-0.244289</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>-0.572915</td>\n","      <td>3.155978</td>\n","      <td>0.226143</td>\n","      <td>-0.852608</td>\n","      <td>-0.552976</td>\n","      <td>3.073297</td>\n","      <td>0.146275</td>\n","      <td>-0.794297</td>\n","      <td>0.218498</td>\n","      <td>-0.099732</td>\n","      <td>...</td>\n","      <td>-0.629591</td>\n","      <td>-0.633300</td>\n","      <td>0.497417</td>\n","      <td>0.226143</td>\n","      <td>0.146275</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da1ac56c-ef82-44b3-b424-3f926f78ff2a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-da1ac56c-ef82-44b3-b424-3f926f78ff2a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-da1ac56c-ef82-44b3-b424-3f926f78ff2a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5ac46bc7-3b84-47f0-ae35-d06d81d47d26\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ac46bc7-3b84-47f0-ae35-d06d81d47d26')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5ac46bc7-3b84-47f0-ae35-d06d81d47d26 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}],"source":["df4 = train_df.iloc[20000:25000]\n","#df4.loc[ df4['Label'] == 2.0, 'Label'] = 1.0\n","df4"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"nEGd9yBVEqGm","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":158,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"c82811a8-974d-4688-e502-fa2639a532f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  \\\n","0            -0.632694        -0.580092         -0.881051        -0.598698   \n","1            -0.712442         1.429695         -0.374214        -0.852608   \n","2            -0.632694        -0.580092         -0.881051        -0.598698   \n","3            -0.512219         0.741109         -0.261913        -0.598698   \n","4             1.709488        -0.580092          1.686548         1.800385   \n","...                ...              ...               ...              ...   \n","24995        -0.859313        -0.387445         -1.006168        -0.852608   \n","24996        -0.859313        -0.387445         -1.006168        -0.852608   \n","24997        -0.345265        -0.387445          0.172427        -0.179720   \n","24998         0.047637        -0.580092         -0.161759         0.152257   \n","24999        -0.572915         3.155978          0.226143        -0.852608   \n","\n","       Bwd Pkt Len Max  Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  \\\n","0            -0.686276        -0.635757         -0.698694        -0.588015   \n","1            -0.536097         3.273131          0.201001        -0.794297   \n","2            -0.686276        -0.635757         -0.698694        -0.588015   \n","3            -0.468995         1.592125         -0.091600        -0.588015   \n","4             1.352691        -0.635757         -0.000646         0.862475   \n","...                ...              ...               ...              ...   \n","24995        -0.849295        -0.434899         -0.814463        -0.794297   \n","24996        -0.849295        -0.434899         -0.814463        -0.794297   \n","24997        -0.599862        -0.434899         -0.552996        -0.529172   \n","24998         1.851568        -0.635757          2.840908         2.244565   \n","24999        -0.552976         3.073297          0.146275        -0.794297   \n","\n","       Flow Byts/s  Flow Pkts/s  ...  Pkt Len Std  Pkt Len Var  Pkt Size Avg  \\\n","0        -0.085003     0.369437  ...    -0.694505    -0.517268     -0.835366   \n","1        -0.068330    -0.136598  ...    -0.490374    -0.598422      0.082195   \n","2        -0.085003    -0.164555  ...    -0.694505    -0.517268     -0.835366   \n","3        -0.081888    -0.163937  ...    -0.416409    -0.490281     -0.084858   \n","4        -0.084752    -0.164529  ...     0.844407     0.309143      0.273510   \n","...            ...          ...  ...          ...          ...           ...   \n","24995    -0.068872    -0.136672  ...    -0.904707    -0.660804     -1.001200   \n","24996    -0.068872    -0.136676  ...    -0.904707    -0.660804     -1.001200   \n","24997    -0.068601    -0.136610  ...    -0.522316    -0.607670     -0.423177   \n","24998    -0.084813    -0.164547  ...     2.041468     2.094844      1.533713   \n","24999     0.218498    -0.099732  ...    -0.629591    -0.633300      0.497417   \n","\n","       Fwd Seg Size Avg  Bwd Seg Size Avg  Init Fwd Win Byts  \\\n","0             -0.881051         -0.698694           0.130146   \n","1             -0.374214          0.201001          -0.755270   \n","2             -0.881051         -0.698694          -0.468538   \n","3             -0.261913         -0.091600          -0.468538   \n","4              1.686548         -0.000646           0.481678   \n","...                 ...               ...                ...   \n","24995         -1.006168         -0.814463          -0.737969   \n","24996         -1.006168         -0.814463          -0.737580   \n","24997          0.172427         -0.552996          -0.116783   \n","24998         -0.161759          2.840908           0.481678   \n","24999          0.226143          0.146275          -0.755270   \n","\n","       Init Bwd Win Byts  Fwd Seg Size Min  Idle Min  Label  \n","0              -0.314942          0.680731 -0.344192    0.0  \n","1              -0.426041         -1.445423 -0.361189    0.0  \n","2              -0.314942         -2.426335  1.906829    0.0  \n","3              -0.314942         -1.183509 -0.344192    0.0  \n","4               4.010477          0.680731 -0.344192    0.0  \n","...                  ...               ...       ...    ...  \n","24995          -0.426041          1.105003 -0.361189    1.0  \n","24996          -0.426041          1.105003  0.117167    1.0  \n","24997          -0.425994         -0.170210 -0.361189    0.0  \n","24998          -0.244289          0.680731 -0.344192    0.0  \n","24999          -0.426041         -1.445423 -0.361189    0.0  \n","\n","[25000 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-1e52b2c5-8c56-402a-9682-7d9ffb71dc7b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fwd Pkt Len Max</th>\n","      <th>Fwd Pkt Len Min</th>\n","      <th>Fwd Pkt Len Mean</th>\n","      <th>Fwd Pkt Len Std</th>\n","      <th>Bwd Pkt Len Max</th>\n","      <th>Bwd Pkt Len Min</th>\n","      <th>Bwd Pkt Len Mean</th>\n","      <th>Bwd Pkt Len Std</th>\n","      <th>Flow Byts/s</th>\n","      <th>Flow Pkts/s</th>\n","      <th>...</th>\n","      <th>Pkt Len Std</th>\n","      <th>Pkt Len Var</th>\n","      <th>Pkt Size Avg</th>\n","      <th>Fwd Seg Size Avg</th>\n","      <th>Bwd Seg Size Avg</th>\n","      <th>Init Fwd Win Byts</th>\n","      <th>Init Bwd Win Byts</th>\n","      <th>Fwd Seg Size Min</th>\n","      <th>Idle Min</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>0.369437</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>0.130146</td>\n","      <td>-0.314942</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.712442</td>\n","      <td>1.429695</td>\n","      <td>-0.374214</td>\n","      <td>-0.852608</td>\n","      <td>-0.536097</td>\n","      <td>3.273131</td>\n","      <td>0.201001</td>\n","      <td>-0.794297</td>\n","      <td>-0.068330</td>\n","      <td>-0.136598</td>\n","      <td>...</td>\n","      <td>-0.490374</td>\n","      <td>-0.598422</td>\n","      <td>0.082195</td>\n","      <td>-0.374214</td>\n","      <td>0.201001</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.632694</td>\n","      <td>-0.580092</td>\n","      <td>-0.881051</td>\n","      <td>-0.598698</td>\n","      <td>-0.686276</td>\n","      <td>-0.635757</td>\n","      <td>-0.698694</td>\n","      <td>-0.588015</td>\n","      <td>-0.085003</td>\n","      <td>-0.164555</td>\n","      <td>...</td>\n","      <td>-0.694505</td>\n","      <td>-0.517268</td>\n","      <td>-0.835366</td>\n","      <td>-0.881051</td>\n","      <td>-0.698694</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-2.426335</td>\n","      <td>1.906829</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.512219</td>\n","      <td>0.741109</td>\n","      <td>-0.261913</td>\n","      <td>-0.598698</td>\n","      <td>-0.468995</td>\n","      <td>1.592125</td>\n","      <td>-0.091600</td>\n","      <td>-0.588015</td>\n","      <td>-0.081888</td>\n","      <td>-0.163937</td>\n","      <td>...</td>\n","      <td>-0.416409</td>\n","      <td>-0.490281</td>\n","      <td>-0.084858</td>\n","      <td>-0.261913</td>\n","      <td>-0.091600</td>\n","      <td>-0.468538</td>\n","      <td>-0.314942</td>\n","      <td>-1.183509</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.709488</td>\n","      <td>-0.580092</td>\n","      <td>1.686548</td>\n","      <td>1.800385</td>\n","      <td>1.352691</td>\n","      <td>-0.635757</td>\n","      <td>-0.000646</td>\n","      <td>0.862475</td>\n","      <td>-0.084752</td>\n","      <td>-0.164529</td>\n","      <td>...</td>\n","      <td>0.844407</td>\n","      <td>0.309143</td>\n","      <td>0.273510</td>\n","      <td>1.686548</td>\n","      <td>-0.000646</td>\n","      <td>0.481678</td>\n","      <td>4.010477</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136672</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737969</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>-0.361189</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>-0.859313</td>\n","      <td>-0.387445</td>\n","      <td>-1.006168</td>\n","      <td>-0.852608</td>\n","      <td>-0.849295</td>\n","      <td>-0.434899</td>\n","      <td>-0.814463</td>\n","      <td>-0.794297</td>\n","      <td>-0.068872</td>\n","      <td>-0.136676</td>\n","      <td>...</td>\n","      <td>-0.904707</td>\n","      <td>-0.660804</td>\n","      <td>-1.001200</td>\n","      <td>-1.006168</td>\n","      <td>-0.814463</td>\n","      <td>-0.737580</td>\n","      <td>-0.426041</td>\n","      <td>1.105003</td>\n","      <td>0.117167</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>-0.345265</td>\n","      <td>-0.387445</td>\n","      <td>0.172427</td>\n","      <td>-0.179720</td>\n","      <td>-0.599862</td>\n","      <td>-0.434899</td>\n","      <td>-0.552996</td>\n","      <td>-0.529172</td>\n","      <td>-0.068601</td>\n","      <td>-0.136610</td>\n","      <td>...</td>\n","      <td>-0.522316</td>\n","      <td>-0.607670</td>\n","      <td>-0.423177</td>\n","      <td>0.172427</td>\n","      <td>-0.552996</td>\n","      <td>-0.116783</td>\n","      <td>-0.425994</td>\n","      <td>-0.170210</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>0.047637</td>\n","      <td>-0.580092</td>\n","      <td>-0.161759</td>\n","      <td>0.152257</td>\n","      <td>1.851568</td>\n","      <td>-0.635757</td>\n","      <td>2.840908</td>\n","      <td>2.244565</td>\n","      <td>-0.084813</td>\n","      <td>-0.164547</td>\n","      <td>...</td>\n","      <td>2.041468</td>\n","      <td>2.094844</td>\n","      <td>1.533713</td>\n","      <td>-0.161759</td>\n","      <td>2.840908</td>\n","      <td>0.481678</td>\n","      <td>-0.244289</td>\n","      <td>0.680731</td>\n","      <td>-0.344192</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>-0.572915</td>\n","      <td>3.155978</td>\n","      <td>0.226143</td>\n","      <td>-0.852608</td>\n","      <td>-0.552976</td>\n","      <td>3.073297</td>\n","      <td>0.146275</td>\n","      <td>-0.794297</td>\n","      <td>0.218498</td>\n","      <td>-0.099732</td>\n","      <td>...</td>\n","      <td>-0.629591</td>\n","      <td>-0.633300</td>\n","      <td>0.497417</td>\n","      <td>0.226143</td>\n","      <td>0.146275</td>\n","      <td>-0.755270</td>\n","      <td>-0.426041</td>\n","      <td>-1.445423</td>\n","      <td>-0.361189</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows Ã— 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e52b2c5-8c56-402a-9682-7d9ffb71dc7b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1e52b2c5-8c56-402a-9682-7d9ffb71dc7b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1e52b2c5-8c56-402a-9682-7d9ffb71dc7b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c4e91656-1337-4cd6-bf5d-5af4759cd13d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4e91656-1337-4cd6-bf5d-5af4759cd13d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c4e91656-1337-4cd6-bf5d-5af4759cd13d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}],"source":["df_final = pd.concat([df0,df1, df2,df3,df4])#df6,df7,df8,df9,df10])\n","df_final"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ewcOrHRfFV0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":11,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"9f21b89d-ebc9-4c1c-8b7d-2ae03ea63360"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    15532\n","1.0     9468\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":16}],"source":["df_final['Label'].value_counts()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"iVL0Bz2gFV9V","executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":9,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["#First get the labels and then drop it. Dont run it first.\n","\n","df0_arr = df0.drop(columns=['Label'])\n","df1_arr = df1.drop(columns=['Label'])\n","df2_arr = df2.drop(columns=['Label'])\n","df3_arr = df3.drop(columns=['Label'])\n","df4_arr = df4.drop(columns=['Label'])\n","#df5_arr = df5.drop(columns=['Label'])\n","# df6_arr = df6.drop(columns=['Label'])\n","# df7_arr = df7.drop(columns=['Label'])\n","# df8_arr = df8.drop(columns=['Label'])\n","# df9_arr = df9.drop(columns=['Label'])\n","# df10_arr = df10.drop(columns=['Label'])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Gri5gXocFsJS","executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["df0_arr = df0_arr.to_numpy()\n","df1_arr = df1_arr.to_numpy()\n","df2_arr = df2_arr.to_numpy()\n","df3_arr = df3_arr.to_numpy()\n","df4_arr = df4_arr.to_numpy()\n","#df5_arr = df5_arr.to_numpy()\n","# df6_arr = df6_arr.to_numpy()\n","# df7_arr = df7_arr.to_numpy()\n","# df8_arr = df8_arr.to_numpy()\n","# df9_arr = df9_arr.to_numpy()\n","# df10_arr = df10_arr.to_numpy()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"0gVhhe6fFvKZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"383dd798-01e0-4998-dd27-27227c46bb6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 5000, 29)"]},"metadata":{},"execution_count":19}],"source":["df0_arr = df0_arr.reshape(1,df0_arr.shape[0],df0_arr.shape[1])\n","df0_arr.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"drx-HZKNFyuH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":7,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"78cb16be-a557-4a28-f237-117db6028a99"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 5000, 29)"]},"metadata":{},"execution_count":20}],"source":["df1_arr = df1_arr.reshape(1,df1_arr.shape[0],df1_arr.shape[1])\n","df1_arr.shape"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"lUj3yI6zFyyM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":7,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"b9d8ff7f-fadc-43bf-8f3a-d914df94b8ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 5000, 29)"]},"metadata":{},"execution_count":21}],"source":["df2_arr = df2_arr.reshape(1,df2_arr.shape[0],df2_arr.shape[1])\n","df2_arr.shape"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"eYsa21EzFy0-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":6,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"43720a31-ac14-4dc6-e621-b1621cf99a8a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 5000, 29)"]},"metadata":{},"execution_count":22}],"source":["df3_arr = df3_arr.reshape(1,df3_arr.shape[0],df3_arr.shape[1])\n","df3_arr.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"lRUIqkgVFy3h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262762,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"8167aa0c-8d09-4d44-f277-1f4bb146f3d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 5000, 29)"]},"metadata":{},"execution_count":23}],"source":["df4_arr = df4_arr.reshape(1,df4_arr.shape[0],df4_arr.shape[1])\n","df4_arr.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"EEN5UuMjGEBx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262763,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"40e9973a-85b2-4254-eea7-70337f93742a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 5000, 29)"]},"metadata":{},"execution_count":24}],"source":["data_final_train = np.vstack((df0_arr,df1_arr,df2_arr,df3_arr,df4_arr))#df6_arr,df7_arr,df8_arr,df9_arr,df10_arr))\n","data_final_train.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"IWPPq_DiGI8A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186262763,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"3416fca4-6d75-4bd6-c252-dca7b9a2d7ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        0.0\n","1        0.0\n","2        0.0\n","3        0.0\n","4        0.0\n","        ... \n","24995    1.0\n","24996    1.0\n","24997    0.0\n","24998    0.0\n","24999    0.0\n","Name: Label, Length: 25000, dtype: float64"]},"metadata":{},"execution_count":25}],"source":["labels = pd.concat([df0['Label'],df1['Label'],df2['Label'],df3['Label'], df4['Label']])\n","labels"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"yKRnfeIlGMhv","executionInfo":{"status":"ok","timestamp":1696186262763,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["labels = labels.to_numpy()"]},{"cell_type":"code","source":[],"metadata":{"id":"2JbJ2-ej6_O9","executionInfo":{"status":"ok","timestamp":1696186262763,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"BLezlAVqyeTO","executionInfo":{"status":"ok","timestamp":1696186263550,"user_tz":240,"elapsed":791,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["BOT_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/BOT.csv')"]},{"cell_type":"code","source":["BOT_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hw0FtmD5UEBB","executionInfo":{"status":"ok","timestamp":1696186263551,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"ea13e45b-6320-4768-fd0c-09f966aad400"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":29,"metadata":{"id":"tdSnI5zVy14g","executionInfo":{"status":"ok","timestamp":1696186263551,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["X_BOT_test = BOT_test.drop(labels = ['Label'], axis=1)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"gwaHv5N2y2Dp","executionInfo":{"status":"ok","timestamp":1696186263551,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["X_BOT_test = X_BOT_test.to_numpy()"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"IK_IqdOhy2G9","executionInfo":{"status":"ok","timestamp":1696186263551,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["y_BOT_test = BOT_test['Label']"]},{"cell_type":"code","source":["y_BOT_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GV9ZvhnLJMt5","executionInfo":{"status":"ok","timestamp":1696186263708,"user_tz":240,"elapsed":159,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"6ed04cb2-3d56-4d1f-f7db-e60866f68bf3"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    10000\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","execution_count":33,"metadata":{"id":"neCGc3bMKT8K","executionInfo":{"status":"ok","timestamp":1696186263708,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["y_BOT_test[y_BOT_test>1.0] = 1.0"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"34Iy_GYgzW-K","executionInfo":{"status":"ok","timestamp":1696186263708,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["y_BOT_test = y_BOT_test.to_numpy()"]},{"cell_type":"code","source":[],"metadata":{"id":"501k9OavNqVl","executionInfo":{"status":"ok","timestamp":1696186263708,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["RARE_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/RARE.csv')"],"metadata":{"id":"ux2AHkSX6iO8","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":579,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["RARE_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2dcUmpaUA2K","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"29d80759-ee22-4de2-be48-d2133bd292d1"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["X_RARE_test = RARE_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"aO9rM07J6njp","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["X_RARE_test = X_RARE_test.to_numpy()"],"metadata":{"id":"r7xaVHob6tqa","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["y_RARE_test = RARE_test['Label']"],"metadata":{"id":"1ng5Yvzv6w7k","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["y_RARE_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGsEJ6PfJa7x","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"ddbec48d-09be-472e-961b-d8c3f6151102"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    566\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["y_RARE_test[y_RARE_test>1.0] = 1.0"],"metadata":{"id":"nwMU2Kze6zhr","executionInfo":{"status":"ok","timestamp":1696186264283,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["y_RARE_test = y_RARE_test.to_numpy()"],"metadata":{"id":"H3z9p3Y-621J","executionInfo":{"status":"ok","timestamp":1696186264284,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kAVrdmCHNrdK","executionInfo":{"status":"ok","timestamp":1696186264284,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["SlowHTTPTest_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/SlowHTTPTest.csv')"],"metadata":{"id":"J2EAu1m9Juo_","executionInfo":{"status":"ok","timestamp":1696186271596,"user_tz":240,"elapsed":7315,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["SlowHTTPTest_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUeB9kfWT9YB","executionInfo":{"status":"ok","timestamp":1696186271597,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"9630d11d-e4e1-48f1-d30a-0d2041dd2e7f"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["X_SlowHTTPTest_test = SlowHTTPTest_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"e1VfT_jrJ3w8","executionInfo":{"status":"ok","timestamp":1696186271597,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["X_SlowHTTPTest_test = X_SlowHTTPTest_test.to_numpy()"],"metadata":{"id":"ihcdP5TVJ7x7","executionInfo":{"status":"ok","timestamp":1696186271597,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["y_SlowHTTPTest_test = SlowHTTPTest_test['Label']"],"metadata":{"id":"pProSogILjlv","executionInfo":{"status":"ok","timestamp":1696186271793,"user_tz":240,"elapsed":200,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["y_SlowHTTPTest_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxJguzAaJ_T3","executionInfo":{"status":"ok","timestamp":1696186271794,"user_tz":240,"elapsed":6,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"795ebbe8-951c-4dd6-fb91-c5944e4895d2"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    461912\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["y_SlowHTTPTest_test[y_SlowHTTPTest_test>1.0] = 1.0"],"metadata":{"id":"PIeMnYPRKCtQ","executionInfo":{"status":"ok","timestamp":1696186271794,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["y_SlowHTTPTest_test = y_SlowHTTPTest_test.to_numpy()"],"metadata":{"id":"UgVlAx3gLtXf","executionInfo":{"status":"ok","timestamp":1696186271794,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ev2B3ULQLyqY","executionInfo":{"status":"ok","timestamp":1696186271794,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["OOD_INFIL_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/OOD_INFIL.csv')"],"metadata":{"id":"hOvRT2h7MN9I","executionInfo":{"status":"ok","timestamp":1696186272951,"user_tz":240,"elapsed":1160,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["OOD_INFIL_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8g_3xNA5T1QC","executionInfo":{"status":"ok","timestamp":1696186272951,"user_tz":240,"elapsed":16,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"91023346-7ab4-4200-ea81-01fc4340f8cc"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["X_OOD_INFIL_test = OOD_INFIL_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"VEJGZYcDMN9K","executionInfo":{"status":"ok","timestamp":1696186272952,"user_tz":240,"elapsed":12,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["X_OOD_INFIL_test = X_OOD_INFIL_test.to_numpy()"],"metadata":{"id":"4lUnRZF5MN9K","executionInfo":{"status":"ok","timestamp":1696186272952,"user_tz":240,"elapsed":11,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["y_OOD_INFIL_test = OOD_INFIL_test['Label']"],"metadata":{"id":"Wwyudk68MN9L","executionInfo":{"status":"ok","timestamp":1696186272952,"user_tz":240,"elapsed":10,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["y_OOD_INFIL_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hy_NIfjCMN9L","executionInfo":{"status":"ok","timestamp":1696186272952,"user_tz":240,"elapsed":10,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"dae17cce-1873-48d1-9412-89959df10893"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    49504\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["y_OOD_INFIL_test[y_OOD_INFIL_test>1.0] = 1.0"],"metadata":{"id":"c8OBs6ROMN9L","executionInfo":{"status":"ok","timestamp":1696186272953,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["y_OOD_INFIL_test = y_OOD_INFIL_test.to_numpy()"],"metadata":{"id":"BEQ7SxMaMN9M","executionInfo":{"status":"ok","timestamp":1696186272953,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p5B8-x4-MQl1","executionInfo":{"status":"ok","timestamp":1696186272953,"user_tz":240,"elapsed":8,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["DDOS_SOLARIS_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/DDOS_SOLARIS.csv')"],"metadata":{"id":"9t7sf5wxP5-P","executionInfo":{"status":"ok","timestamp":1696186273606,"user_tz":240,"elapsed":660,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["DDOS_SOLARIS_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4FxqEWpS9r4","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":9,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"67cbe458-f5ef-4a58-a438-d808d065a244"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["X_DDOS_SOLARIS_test = DDOS_SOLARIS_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"FYum_XZhP5-Q","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":6,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["X_DDOS_SOLARIS_test = X_DDOS_SOLARIS_test.to_numpy()"],"metadata":{"id":"gEdV5E57P5-R","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":6,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["y_DDOS_SOLARIS_test = DDOS_SOLARIS_test['Label']"],"metadata":{"id":"lJ5lVbdVP5-R","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["y_DDOS_SOLARIS_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6CkF03aP5-R","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"0a20c3a0-9fd7-4c8d-9d9e-03041a75a886"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    10990\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["y_DDOS_SOLARIS_test[y_DDOS_SOLARIS_test>1.0] = 1.0"],"metadata":{"id":"8Ihr044nP5-R","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["y_DDOS_SOLARIS_test = y_DDOS_SOLARIS_test.to_numpy()"],"metadata":{"id":"a55GgrduP5-R","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q5vSQd-dQiJm","executionInfo":{"status":"ok","timestamp":1696186273607,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["DDOS_HOIC_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/DDOS_HOIC.csv')"],"metadata":{"id":"OPt0FupfRg6p","executionInfo":{"status":"ok","timestamp":1696186280732,"user_tz":240,"elapsed":7128,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["DDOS_HOIC_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WR92c5rGS6Zl","executionInfo":{"status":"ok","timestamp":1696186280903,"user_tz":240,"elapsed":176,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"c1e1a576-3f7c-403c-f4e2-58dbbfdfd4a8"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["X_DDOS_HOIC_test = DDOS_HOIC_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"hlpwIV7oRg6q","executionInfo":{"status":"ok","timestamp":1696186280903,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["X_DDOS_HOIC_test = X_DDOS_HOIC_test.to_numpy()"],"metadata":{"id":"Uipksm-oRg6r","executionInfo":{"status":"ok","timestamp":1696186280903,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["y_DDOS_HOIC_test = DDOS_HOIC_test['Label']"],"metadata":{"id":"77R4ewAdRg6s","executionInfo":{"status":"ok","timestamp":1696186280904,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["y_DDOS_HOIC_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186280904,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"46311ae7-aec9-45e6-ddc3-c6b624047154","id":"3FrY6hf2Rg6s"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    686012\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["y_DDOS_HOIC_test[y_DDOS_HOIC_test>1.0] = 1.0"],"metadata":{"id":"6sONLIVBRg6s","executionInfo":{"status":"ok","timestamp":1696186280904,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["y_DDOS_HOIC_test = y_DDOS_HOIC_test.to_numpy()"],"metadata":{"id":"f4xqloRQRg6t","executionInfo":{"status":"ok","timestamp":1696186280904,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qy7Mh9hJQlj0","executionInfo":{"status":"ok","timestamp":1696186280904,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["DDOS_GOLDEN_EYE_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/DDOS_GOLDEN_EYE.csv')"],"metadata":{"id":"wEZftlpGSSHP","executionInfo":{"status":"ok","timestamp":1696186281913,"user_tz":240,"elapsed":1011,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["DDOS_GOLDEN_EYE_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjSv5pGIS2CA","executionInfo":{"status":"ok","timestamp":1696186281914,"user_tz":240,"elapsed":10,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"371d0fa5-9c60-4d9e-8b29-fd7a0d485575"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["X_DDOS_GOLDEN_EYE_test = DDOS_GOLDEN_EYE_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"Ciz0zl7ASSHP","executionInfo":{"status":"ok","timestamp":1696186281914,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["X_DDOS_GOLDEN_EYE_test = X_DDOS_GOLDEN_EYE_test.to_numpy()"],"metadata":{"id":"HS13KkOpSSHQ","executionInfo":{"status":"ok","timestamp":1696186281914,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["y_DDOS_GOLDEN_EYE_test = DDOS_GOLDEN_EYE_test['Label']"],"metadata":{"id":"3Q6gIeI_SSHQ","executionInfo":{"status":"ok","timestamp":1696186282076,"user_tz":240,"elapsed":165,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["y_DDOS_GOLDEN_EYE_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186282077,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"0f4aed02-7dd6-44bd-bfba-054dfe76be43","id":"L-gBqvnnSSHR"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    41508\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["y_DDOS_GOLDEN_EYE_test[y_DDOS_GOLDEN_EYE_test>1.0] = 1.0"],"metadata":{"id":"jsHb1THdSSHR","executionInfo":{"status":"ok","timestamp":1696186282077,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["y_DDOS_GOLDEN_EYE_test = y_DDOS_GOLDEN_EYE_test.to_numpy()"],"metadata":{"id":"j28EPvAsSSHS","executionInfo":{"status":"ok","timestamp":1696186282077,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"szDmPRr1THAN","executionInfo":{"status":"ok","timestamp":1696186282077,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["BENIGN_TEST_test = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/BENIGN_TEST.csv')"],"metadata":{"id":"Eiq6T905TOgk","executionInfo":{"status":"ok","timestamp":1696186282527,"user_tz":240,"elapsed":452,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["BENIGN_TEST_test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGRl8SjKStM5","executionInfo":{"status":"ok","timestamp":1696186282527,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"a7a3e090-0cb2-4e24-f822-b6433ea134cc"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Fwd Pkt Len Max      0\n","Fwd Pkt Len Min      0\n","Fwd Pkt Len Mean     0\n","Fwd Pkt Len Std      0\n","Bwd Pkt Len Max      0\n","Bwd Pkt Len Min      0\n","Bwd Pkt Len Mean     0\n","Bwd Pkt Len Std      0\n","Flow Byts/s          0\n","Flow Pkts/s          0\n","Bwd IAT Tot          0\n","Bwd IAT Mean         0\n","Bwd IAT Std          0\n","Bwd IAT Max          0\n","Bwd IAT Min          0\n","Fwd Pkts/s           0\n","Bwd Pkts/s           0\n","Pkt Len Min          0\n","Pkt Len Max          0\n","Pkt Len Mean         0\n","Pkt Len Std          0\n","Pkt Len Var          0\n","Pkt Size Avg         0\n","Fwd Seg Size Avg     0\n","Bwd Seg Size Avg     0\n","Init Fwd Win Byts    0\n","Init Bwd Win Byts    0\n","Fwd Seg Size Min     0\n","Idle Min             0\n","Label                0\n","dtype: int64"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["X_BENIGN_TEST_test = BENIGN_TEST_test.drop(labels = ['Label'], axis=1)"],"metadata":{"id":"gXpwC8kcTOgm","executionInfo":{"status":"ok","timestamp":1696186282527,"user_tz":240,"elapsed":1,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["X_BENIGN_TEST_test = X_BENIGN_TEST_test.to_numpy()"],"metadata":{"id":"SdyqixYdTOgm","executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["y_BENIGN_TEST_test = BENIGN_TEST_test['Label']"],"metadata":{"id":"ISRJ8RIUTOgn","executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["y_BENIGN_TEST_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"abf49753-a397-42c6-a82f-2e0602563631","id":"9t_IHDyqTOgn"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    9946\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["y_BENIGN_TEST_test[y_BENIGN_TEST_test>1.0] = 1.0"],"metadata":{"id":"R6hrq7BTTOgo","executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["y_BENIGN_TEST_test = y_BENIGN_TEST_test.to_numpy()"],"metadata":{"id":"-T-8bXNvTOgo","executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":1,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","execution_count":91,"metadata":{"id":"3k8maakrn2Cm","executionInfo":{"status":"ok","timestamp":1696186282689,"user_tz":240,"elapsed":1,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"Qju3HMfFk4SC","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":134,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["def construct_pair(X_list_train):  # 3 * 1000 * 29\n","  n_dom = len(X_list_train) # 4 * 1000 * 29\n","  X_in = np.vstack(X_list_train)  ## 3000 * 29 # orignial data with all classes/labels\n","  print(\"Xin SHAPE TRAIN DATA\", X_in.shape)\n","  X_outs = [] # ground truth data #3 * 1000 * 29\n","  for i in range(0, n_dom): # for each domain\n","      X = X_list_train[i]  # take first domain 1 * 1000 * 29\n","      Z_list = []\n","      for j in range(0, n_dom):\n","          Z_list.append(X) # make 3 (num of domains) copies of the same 1000 samples. 3 * 1000 * 29\n","      Z = np.vstack(Z_list) # Z shape: 3000 * 29 # one domain data copied three times\n","      X_outs.append(Z) #  3 * 3000 * 29 ## all class samples stacked to nos of domains.\n","  return X_in, X_outs"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"gpYcxOxilc2A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"9c93c135-2cc2-4d4a-a509-f3dff499ff3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE TRAIN DATA: (5, 5000, 29)\n","Ytrain shape: (25000,)\n","Ytrain : [0. 0. 0. ... 0. 0. 0.]\n","Xin SHAPE TRAIN DATA (25000, 29)\n","X_in SHAPE: (25000, 29)\n","X_out SHAPE: 5\n"]}],"source":["X_list_train = data_final_train\n","print (\"SHAPE TRAIN DATA:\", X_list_train.shape)\n","\n","Y_train = labels\n","print (\"Ytrain shape:\", Y_train.shape)\n","print (\"Ytrain :\", Y_train)\n","\n","X_in, X_outs = construct_pair(X_list_train)\n","\n","print (\"X_in SHAPE:\", X_in.shape) # 20000 * 29 # stacked original data\n","print (\"X_out SHAPE:\", len(X_outs)) # 4 * 20000 * 29\n","\n","normed = X_in"]},{"cell_type":"code","source":["print(len(X_list_train), len(X_outs), X_list_train[0].shape, X_outs[0].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwcgONGiR8hQ","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"47ba204b-8c4a-47b8-8778-1fa9201d96ce"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["5 5 (5000, 29) (25000, 29)\n"]}]},{"cell_type":"code","execution_count":95,"metadata":{"id":"Bxi6PluAlRzn","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["class Dataset(dataset):\n","    def __init__(self, train=True, dom=0):\n","        super(Dataset, self).__init__()\n","\n","        #print (\"DOMAIN >>>>>>>>>>>:\", dom)\n","        self.dom = dom\n","\n","        if train:\n","            self.inputs = normed  # inputs of all domains\n","            self.outs = X_outs[self.dom]  # the matrix of replicated data sets taken from the lth domain # 1 * 20000 * 29\n","            self.targets = Y_train\n","            self.dom0 = X_outs[0]\n","            self.dom1 = X_outs[1]\n","            self.dom2 = X_outs[2]\n","            self.dom3 = X_outs[3]\n","            self.dom4 = X_outs[4]\n","            # self.dom = []\n","            # for i in range(len(X_list_train)):\n","            #  self.dom.append(X_list_train[i])\n","        else:\n","            (self.inputs, self.outs) = (X_test_in4, y_test_in4)\n","\n","        # self.images = self.images.reshape(-1, 1, 256)\n","\n","    def __getitem__(self, index):\n","        input = self.inputs[index]\n","        output = self.outs[index]\n","        targets = self.targets[index]\n","        dominp = (self.dom0[index], self.dom1[index], self.dom2[index], self.dom3[index], self.dom4[index])\n","        #dominp = tuple(self.dom)\n","        return input, output, targets, dominp  ## input 3000 * 29 , output 1 * 3000 * 29\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    pass\n"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"b5zlt1t_n766","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["epochs = 100\n","batch_size = 200\n","feats = 29\n","domains = 5\n","classes = 2\n","latent_dims = 7\n","learning_rate = 0.009"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"cgh5rmAOY1Wz","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["#model = Autoencoder().to(device)\n","criterion = nn.MSELoss()"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"Hmp_6D42oATg","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["class MultitaskAutoencoder(nn.Module):\n","    def __init__(self, D_in, H=20, H2=14, latent_dim=7):\n","        # Encoder\n","        super(MultitaskAutoencoder, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H)  # 29 * 20\n","        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n","        self.linear2 = nn.Linear(H, H2)  # 20 * 10\n","        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n","        self.linear3 = nn.Linear(H2, H2)  # 10 * 10\n","        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n","        self.num_class = classes\n","\n","        self.fc1 = nn.Linear(H2, latent_dim)  # 10 * 7\n","\n","        self.classifier = nn.Linear(latent_dim, self.num_class)  # 7 * 3\n","\n","        # classifier\n","        # self.classifier = nn.Linear(latent_dim, self.num_class) # 7 * 3\n","\n","        #         # Decoder\n","        self.fc3 = nn.Linear(latent_dim, latent_dim)  # 7 * 7\n","        #         self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n","        self.fc4 = nn.Linear(latent_dim, H2)  # 7 * 10\n","        #         self.fc_bn4 = nn.BatchNorm1d(H2)\n","\n","        self.linear4 = nn.Linear(H2, H2)  # 10 * 10\n","        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n","        self.linear5 = nn.Linear(H2, H)  # 10 * 20\n","        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n","        self.linear6 = nn.Linear(H, D_in)  # 20 * 29\n","        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n","        self.relu = nn.ReLU()\n","\n","    def encode(self, x):\n","        lin1 = self.relu(self.lin_bn1(self.linear1(x)))  # 29 * 20\n","        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))  # 20 * 10\n","        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))  # 10 * 10\n","\n","        fc1 = self.relu(self.fc1(lin3))  # 10 * 7\n","        # fc2 = F.relu(self.classifier(fc1)) # 7 * 3\n","        return fc1\n","\n","    def decode(self, z):\n","        fc3 = self.relu(self.fc3(z))  # 7 * 7\n","        fc4 = self.relu(self.fc4(fc3))  # .view(128, -1) # 7 * 10\n","\n","        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))  # 10 * 10\n","        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))  # 10 * 20\n","        return self.lin_bn6(self.linear6(lin5))  # 20 * 29\n","\n","    def forward(self, inputs):  #batch * feats\n","        z = self.encode(inputs)  # 29 * 3\n","        logits = self.classifier(z)\n","        reconstruction = self.decode(z)\n","\n","        return logits, reconstruction, z"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"SZvgwAbKXnPt","executionInfo":{"status":"ok","timestamp":1696186282822,"user_tz":240,"elapsed":2,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["class customLoss(nn.Module):\n","    def __init__(self):\n","        super(customLoss, self).__init__()\n","        self.mse_loss = nn.MSELoss()\n","        self.classification_criterion = nn.CrossEntropyLoss()\n","\n","    def calculate_gram_mat(self,X, sigma):  # required only for codes\n","        \"\"\"calculate gram matrix for variables x\n","            Args:\n","            x: random variable with two dimensional (N,d).\n","            sigma: kernel size of x (Gaussain kernel)\n","        Returns:\n","            Gram matrix (N,N)\n","        \"\"\"\n","        x = X.view(X.shape[0], -1)\n","        instances_norm = torch.sum(x ** 2, -1).reshape((-1, 1))\n","        dist = -2 * torch.mm(x, x.t()) + instances_norm + instances_norm.t()\n","\n","        return torch.exp(-dist / sigma)\n","\n","    def renyi_entropy(self, code, sigma):  # code is batch * latent dim\n","        # calculate entropy for single variables x (Eq.(9) in paper)\n","        #         Args:\n","        #         x: random variable with two dimensional (N,d).\n","        #         sigma: kernel size of x (Gaussain kernel)\n","        #         alpha:  alpha value of renyi entropy\n","        #     Returns:\n","        #         renyi alpha entropy of x.\n","\n","        alpha = 2  ## Renyi's 2nd order entropya\n","\n","        # calculate kernel with new updated sigma\n","        code_k = self.calculate_gram_mat(code, sigma)\n","        code_k = code_k / torch.trace(code_k)\n","        # eigv = torch.abs(torch.symeig(k, eigenvectors=True)[0])\n","        eigv, eigvec = torch.linalg.eigh(code_k)\n","        eig_pow = eigv ** alpha\n","        entropy = (1 / (1 - alpha)) * torch.log2(torch.sum(eig_pow))\n","        # entropy = -torch.sum(eig_pow)\n","\n","        return entropy\n","\n","    def joint_entropy(self,code, prior, s_x, s_y):  # x = code (batch * feats), y = prior kernel (bacth * batch)\n","\n","        \"\"\"calculate joint entropy for random variable x and y (Eq.(10) in paper)\n","            Args:\n","            x: random variable with two dimensional (N,d).\n","            y: random variable with two dimensional (N,d).\n","            s_x: kernel size of x\n","            s_y: kernel size of y\n","            alpha:  alpha value of renyi entropy\n","        Returns:\n","            joint entropy of x and y.\n","        \"\"\"\n","\n","        alpha = 2\n","\n","        code_k = self.calculate_gram_mat(code, s_x)\n","        prior_k = self.calculate_gram_mat(prior, s_y)\n","        # prior_k = calculate_gram_mat(prior, s_y) ## prior latent kernel 100 * 29\n","\n","        k = torch.mul(code_k, prior_k)\n","        k = k / torch.trace(k)\n","        # eigv = torch.abs(torch.symeig(k, eigenvectors=True)[0])\n","        eigv, eigvec = torch.linalg.eigh(k)\n","        eig_pow = eigv ** alpha\n","        entropy = (1 / (1 - alpha)) * torch.log2(torch.sum(eig_pow))\n","        # entropy = torch.sum(eig_pow)\n","\n","        return entropy\n","\n","    def entropy_loss(self,latent_code, prior_kernel, normalize):  ## calculate MI # x = code , y = prior\n","\n","        \"\"\"calculate Mutual information between random variables x and y\n","        Args:\n","            x: random variable with two dimensional (N,d).\n","            y: random variable with two dimensional (N,d).\n","            s_x: kernel size of x\n","            s_y: kernel size of y\n","            normalize: bool True or False, noramlize value between (0,1)\n","        Returns:\n","            Mutual information between x and y (scale)\n","\n","        \"\"\"\n","        # global s_x\n","        s_x = 0.5  # code\n","        s_y = 0.5  # prior\n","\n","        # entropy of code. code is batch * latent dimension\n","        Hx = self.renyi_entropy(latent_code, sigma=s_x)\n","\n","        # entropy of prior ##For prior, RBF kernel is pre-computed. sigma is not considered\n","        Hy = self.renyi_entropy(prior_kernel, sigma=s_y)\n","\n","        # joint entropy\n","        # Hxy = joint_entropy(x, y, s_x, s_y)\n","        Hxy = self.joint_entropy(latent_code, prior_kernel, s_x, s_y)\n","\n","        if normalize:\n","            # Ixy = Hx + Hy - Hxy\n","            Ixy = ((Hx * Hy) / (Hxy * Hxy))\n","            Ixy = Ixy / (torch.max(Hx, Hy))\n","            #print(\"IXY:\", Ixy)\n","            # Ixy = torch.log2(Ixy)\n","\n","        else:\n","            # Ixy = Hx + Hy - Hxy\n","            Ixy = ((Hx * Hy) / (Hxy * Hxy))\n","            Ixy = Ixy / (torch.max(Hx, Hy))\n","            # Ixy = torch.log2(Ixy)\n","\n","        return Ixy\n","\n","    def forward(self, input, x_recon, Z, dom_out, logits, targets):\n","        loss_MSE = self.mse_loss(x_recon, dom_out)\n","\n","        targets = torch.flatten(targets)\n","        #print (\"TARGETS:\",targets)\n","\n","        classification_loss = self.classification_criterion(logits, targets)\n","        print('Classification Loss: ', classification_loss, 'MSE Loss: ', loss_MSE)\n","        #entropy_loss = self.entropy_loss(input,Z, True)\n","        # mmd_loss = self.mmd_two_distribution(input, Z, [1, 5, 10])\n","        # print('MMD_Loss: ', mmd_loss)\n","\n","        return 1*classification_loss + (0.1 * loss_MSE)"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"bVUSFpCXqWoy","executionInfo":{"status":"ok","timestamp":1696186282964,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["class MMDLoss():\n","  def compute_pairwise_distances(self, x, y):\n","      \"\"\"Computes the squared pairwise Euclidean distances between x and y.\n","      Args:\n","        x: a tensor of shape [num_x_samples, num_features]\n","        y: a tensor of shape [num_y_samples, num_features]\n","      Returns:\n","        a distance matrix of dimensions [num_x_samples, num_y_samples].\n","      \"\"\"\n","      # Define a function to compute the squared Euclidean norm of a tensor\n","      def norm(x):\n","          return torch.sum(torch.square(x), dim=1)\n","\n","      # Compute the squared pairwise Euclidean distances\n","      return norm(torch.unsqueeze(x, 2) - torch.transpose(y, 0, 1))\n","\n","  def rbf_kernel(self, x, y, sigmas):\n","      \"\"\"\n","      compute the rbf kernel value\n","      :param x: [num_x_samples, num_features]\n","      :param y: [num_y_samples, num_features]\n","      :param sigmas: sigmas need to use\n","      :return: single value of x, y kernel\n","      \"\"\"\n","      beta = 1. / (2. * torch.unsqueeze(sigmas, 1))\n","      dist = self.compute_pairwise_distances(x, y)\n","      dot = -torch.matmul(beta, torch.reshape(dist, (1, -1)))\n","      exp = torch.exp(dot)\n","      return torch.mean(exp, dim=1, keepdim=True)\n","\n","  def mmd_two_distribution(self, source, target, sigmas):\n","      \"\"\"\n","      compute mmd loss between two distributions\n","      :param source: [num_samples, num_features]\n","      :param target: [num_samples, num_features]\n","      :return:\n","      \"\"\"\n","\n","      sigmas = torch.tensor(sigmas).to(device)\n","      xy = self.rbf_kernel(source, target, sigmas)\n","      xx = self.rbf_kernel(source, source, sigmas)\n","      yy = self.rbf_kernel(target, target, sigmas)\n","      return xx + yy - 2 * xy\n","\n","  def MMD_Loss_func(self, num_source, y_true, y_pred, sigmas=None):\n","      \"\"\"\n","      MMD loss of multiple sources\n","      :param num_source: number of source domain\n","      :param sigmas: sigma need to use, default: [1, 5, 10]\n","      :return:\n","      \"\"\"\n","      if sigmas is None:\n","          sigmas = [1, 5, 10]\n","\n","      cost = []\n","\n","      for i in range(num_source):\n","          for j in range(num_source):\n","              domain_i = torch.where(y_true == i)[0]\n","              domain_j = torch.where(y_true == j)[0]\n","              single_res = self.mmd_two_distribution(y_pred[domain_i],\n","                                                y_pred[domain_j],\n","                                                sigmas=sigmas)\n","              cost.append(single_res)\n","      cost = torch.cat(cost)\n","      return torch.mean(cost)"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"6nqES7Ycs-DJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696186282964,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"df3db0de-9afe-4de1-ecaa-d328ef74f0d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["D_in shape: 29\n"]}],"source":["D_in = 29\n","print (\"D_in shape:\", D_in)\n","H = 20\n","H2 = 14"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"diYdmc8prDUN","executionInfo":{"status":"ok","timestamp":1696186287871,"user_tz":240,"elapsed":4909,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["og_interval = 50\n","val_losses = []\n","train_losses = []\n","\n","multitaskAE = MultitaskAutoencoder(D_in, H, H2).to(device)\n","optimizer = torch.optim.Adam(multitaskAE.parameters(), lr=learning_rate, weight_decay=1e-3 )"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"VQKajW0IrIC-","executionInfo":{"status":"ok","timestamp":1696186287872,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[],"source":["def train_AE():\n","\n","    for epoch in range(epochs):\n","            train_loss = 0\n","            losses = []\n","\n","            for domain in range(domains):\n","                dataset = Dataset(dom=domain)\n","                dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","                for input, out, targets, dominp in dataloader:\n","                    # data = data.to(device)\n","\n","\n","                    input = input.float().to(device)\n","                    #print (\"INPUTS SHAPE:\", input.shape)\n","\n","                    dom_out = out.float().to(device) # ground truth data\n","                    #print(\"OUTS SHAPE:\", dom_out.shape)\n","\n","                    targets = targets.long().to(device)\n","                    #print (\"TARGETS IN TRAIN:\", targets)\n","\n","                    for i in range(0, len(dominp)):\n","                      dominp[i] = dominp[i].float().to(device)\n","\n","                    logits, recon_batch, Z = multitaskAE(input) ## model\n","                    # print (\"logits train:\", logits)\n","\n","                    loss_mse = customLoss()\n","                    loss = loss_mse(input, recon_batch, Z, dom_out, logits, targets)\n","\n","                    mmd = MMDLoss()\n","                    mmd_loss = []\n","                    for i in range(0, len(dominp)):\n","                      if i != domain:\n","                        mmd_loss.append(mmd.mmd_two_distribution(Z, multitaskAE.encode(dominp[i]), sigmas = [1, 5, 10]))\n","\n","                    print('MMD Loss: ', torch.mean(torch.cat(mmd_loss)))\n","                    loss += 10*torch.mean(torch.cat(mmd_loss))\n","                    losses.append(loss)\n","\n","                    optimizer.zero_grad()\n","\n","            final_loss = torch.mean(torch.stack(losses))\n","\n","            final_loss.backward()\n","            train_loss += final_loss.item()\n","            optimizer.step()\n","\n","            if epochs % 50 == 0:\n","                print('====> Epoch: {} Average loss: {:.4f}'.format(\n","                    epochs, train_loss / len(dataloader.dataset)))\n","                train_losses.append(train_loss / len(dataloader.dataset))"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"uNQ7hN-3rmCS","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"647d7427-3313-4a26-a705-46e613a338cf","executionInfo":{"status":"ok","timestamp":1696187956897,"user_tz":240,"elapsed":1669029,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6394, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5329, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7376, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6262, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6502, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5217, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4807, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6789, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6521, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5298, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9184, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5809, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0215, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5675, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4586, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6232, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7923, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6310, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0209, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0898, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9169, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1583, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0720, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1569, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9445, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2015, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8354, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0494, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9798, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2289, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1448, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5299, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5494, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1130, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0101, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9425, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1302, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3193, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1724, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0130, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0725, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0571, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2465, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1495, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1926, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8203, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9943, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9670, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1658, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1374, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0352, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4964, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1106, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5353, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0605, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9240, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1670, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2277, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1731, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9997, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0736, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9649, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9169, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1953, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2789, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1406, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9175, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1983, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8158, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9850, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9900, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1851, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0128, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5274, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0842, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5298, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1061, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0093, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9524, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1289, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3409, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1274, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0157, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9848, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0133, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9111, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1272, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1049, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2151, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1492, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8785, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1886, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8425, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0546, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9432, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1681, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5295, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0815, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4874, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0420, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0366, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0951, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1788, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9704, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1276, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0755, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0393, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9836, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1326, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9875, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1179, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0690, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9248, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0627, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9969, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2141, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3157, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1046, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1251, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2151, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2600, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2351, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0714, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4570, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5488, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6242, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5871, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5171, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5232, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5383, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5749, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5048, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6057, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4840, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5601, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4345, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5505, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5042, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6368, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7659, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6041, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5829, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6790, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5164, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6476, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5351, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9481, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1094, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1513, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1052, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0228, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0550, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9758, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0886, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9770, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1241, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1215, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0727, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9462, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0208, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9959, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2010, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0776, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2412, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1774, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0635, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9519, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0387, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0240, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0439, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0407, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9095, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0583, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9314, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0855, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1108, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0803, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9060, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9887, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1705, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3037, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1051, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0592, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2375, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1581, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9980, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9185, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1041, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1298, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1029, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0072, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0410, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9298, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0865, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9558, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0883, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1164, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9001, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0135, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3453, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1227, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0822, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1532, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2639, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9974, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2435, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9718, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8917, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8919, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9272, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0319, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3621, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2673, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9744, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1470, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9103, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9463, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8919, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0114, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1063, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1687, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1097, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9397, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2576, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9280, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8737, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1400, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2220, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9906, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9361, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8980, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0467, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2729, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9774, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1419, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0515, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9734, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9583, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1010, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1330, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1909, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9960, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3246, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9528, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1325, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6853, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4540, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4214, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5189, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7766, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4968, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6110, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4269, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5695, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5166, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5771, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6632, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6236, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4928, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7372, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5273, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4261, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4530, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2447, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9987, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9656, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9228, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8854, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0453, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3477, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2968, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1555, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0753, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9453, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9266, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1387, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1237, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1639, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9406, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2715, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0414, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9357, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9063, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1437, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2358, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9907, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8549, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8724, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3576, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1807, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1342, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9954, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9171, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9789, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8970, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1329, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1018, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1536, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0999, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9523, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2920, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0425, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9037, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1393, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9746, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9686, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4078, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2780, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2024, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1589, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2400, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6458, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0099, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3027, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9628, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1678, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8566, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0988, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9543, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1835, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0157, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1581, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0291, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9863, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9502, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4124, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2363, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1643, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1863, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4460, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6146, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9678, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3089, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9553, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9466, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2844, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8721, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8951, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9490, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2874, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1638, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9896, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2140, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1072, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0086, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9983, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4567, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2889, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1646, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1815, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4719, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2795, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6562, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3433, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9296, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9199, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1364, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3088, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8710, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0778, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8990, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2595, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1771, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2358, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1245, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0553, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5115, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8378, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7839, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6180, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6319, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9124, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6912, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1305, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5190, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4269, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4604, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6237, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7167, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4524, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5543, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7775, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5015, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6654, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6004, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5570, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0326, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9475, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4562, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2808, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1782, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1938, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2681, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.7068, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3397, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9388, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2076, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8975, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0745, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8833, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9888, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3296, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2009, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0903, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0835, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0472, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0888, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9114, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1749, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1320, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9049, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3116, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0171, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9485, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2361, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4140, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9430, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2094, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9201, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1470, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8616, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3054, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5661, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9826, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1114, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0643, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9479, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0355, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1527, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2080, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8757, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0218, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9399, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2202, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1624, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4752, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0837, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0231, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8877, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0169, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2226, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2350, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8952, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1424, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8907, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3037, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5333, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1167, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8794, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0491, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1135, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2017, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8490, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3306, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9003, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1702, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1569, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4499, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1133, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0334, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9246, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1950, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2392, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8926, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1620, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8836, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3086, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5636, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0267, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0880, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1062, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0781, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1243, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2188, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9057, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3821, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9617, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2080, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1608, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5186, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0857, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9098, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0070, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2297, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2729, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8979, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2134, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9084, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2811, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5905, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6127, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5850, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5576, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6013, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6413, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7582, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5126, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6676, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5891, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9360, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5733, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5191, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4490, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5427, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6761, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7021, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6287, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4289, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7262, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9558, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","====> Epoch: 100 Average loss: 0.0000\n","Classification Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5030, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5395, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5406, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7483, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6316, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6574, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4148, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5276, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6866, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6646, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5388, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5879, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5824, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5219, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6335, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8044, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6369, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0146, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0882, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9983, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1502, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0696, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2527, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1490, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9391, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1985, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8342, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0452, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9762, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2257, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1375, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5196, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0614, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5508, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9394, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1279, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3114, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1693, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0675, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9671, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9126, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1978, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0567, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2402, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1461, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8862, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8196, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9919, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9587, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1634, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1346, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0308, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4938, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1128, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5292, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0577, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9866, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9244, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1609, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2279, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1650, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9980, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0731, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9651, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9186, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0640, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2732, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1384, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9076, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8154, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9847, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2067, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1801, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0074, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5271, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0772, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5252, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1024, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1266, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3369, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1215, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0123, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9859, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9090, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1225, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1429, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1841, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8429, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0479, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9357, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1636, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1619, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0797, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4834, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0410, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0284, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9381, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0937, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3069, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1741, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9675, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1055, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1217, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0166, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0375, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9805, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1269, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9855, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1133, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1134, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0618, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9160, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0614, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9963, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2068, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3092, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0988, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1238, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2085, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2654, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2239, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0685, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5539, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6339, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5987, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5191, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5292, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5466, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5121, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5804, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4889, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5625, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5151, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6440, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7731, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6085, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5863, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6859, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7038, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5215, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6556, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5378, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9454, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1074, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1457, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0995, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0239, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0236, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0492, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9763, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0826, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9690, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1187, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1183, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9397, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0155, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9935, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1970, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3442, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0783, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1014, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2031, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2389, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1802, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9472, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0566, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1018, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0306, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0171, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0405, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0362, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9056, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9267, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0799, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1129, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9043, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0559, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9888, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1673, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3008, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0978, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0562, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2322, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1537, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9963, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9207, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0990, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1258, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1014, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0442, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9289, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0826, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9540, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0799, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1036, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8970, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0559, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1632, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3380, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1148, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0778, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1486, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2580, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9934, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1519, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0600, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2333, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9721, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8867, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9177, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0288, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3584, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2616, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9705, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0193, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9100, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9412, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0833, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1001, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1636, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1067, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9377, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2532, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8737, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2226, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9891, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9525, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9293, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8921, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0426, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3489, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2661, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9743, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1388, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0447, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9652, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9596, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9526, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0973, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1855, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1145, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9956, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3221, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9507, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9167, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6957, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4924, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4640, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4324, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5252, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7816, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7237, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5073, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6194, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5208, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5796, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5268, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6743, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6252, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5036, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7451, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5421, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4349, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4605, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5850, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2470, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9635, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9200, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8812, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0382, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3453, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2898, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1492, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0680, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9522, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9440, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9208, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1332, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9952, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1188, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1588, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1358, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9347, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2680, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0356, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9353, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9032, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1384, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2316, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9850, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9670, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8515, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8679, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0179, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1811, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1332, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9924, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9113, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9731, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8977, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1328, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9989, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0937, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1466, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1003, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9517, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0357, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9005, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9715, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9636, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4039, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2721, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1982, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1534, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2389, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6355, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3046, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9582, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1642, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3085, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8549, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0926, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8964, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9487, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3218, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1738, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1890, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1515, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0250, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9830, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9476, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4103, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2360, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1561, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1793, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4430, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2028, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6080, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9621, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3059, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9513, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1651, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2806, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0248, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8922, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9487, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2818, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9799, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0988, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9894, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4548, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2831, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1636, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1737, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2741, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6596, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0167, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3360, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9227, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9139, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1354, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3019, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8679, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0755, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8963, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9718, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1733, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2260, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1209, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0523, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5090, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8413, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7923, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6264, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6363, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9253, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6960, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1301, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8479, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4357, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4728, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6268, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7229, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5617, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4842, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4852, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7835, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5122, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6739, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6038, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0287, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9416, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4545, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2795, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1730, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1902, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4987, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2599, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.7000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9595, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3381, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9350, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9602, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2019, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2585, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8940, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0687, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8846, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9873, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3246, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1969, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0839, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2293, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0806, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0960, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0147, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0401, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9067, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0280, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1727, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1318, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8989, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3115, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9478, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2313, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0887, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0829, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9351, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9949, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1637, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2097, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9130, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1437, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8602, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3055, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5598, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9767, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1047, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0635, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9408, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0267, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1525, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8685, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0126, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2205, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1571, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0786, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8864, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2160, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2321, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8931, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1434, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8855, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9931, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1061, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1087, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8785, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0468, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1079, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8504, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3264, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0198, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8994, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1673, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1477, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4499, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1078, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0314, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9191, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1911, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1494, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8847, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3006, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5601, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0845, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1029, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9417, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0725, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2132, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9005, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3770, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9908, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9557, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1554, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5140, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0830, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9106, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2287, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2653, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8927, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2071, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9027, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2776, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5872, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5082, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6194, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5960, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4469, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5668, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6093, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6489, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4331, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7581, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5198, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4671, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6735, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5844, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5543, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6818, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7139, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4372, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6383, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7322, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9609, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","====> Epoch: 100 Average loss: 0.0000\n","Classification Loss:  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5207, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5624, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5238, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6634, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5643, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7652, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6480, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6816, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4219, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5499, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5128, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7153, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6773, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5721, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9404, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6101, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0491, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5390, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6495, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6594, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0125, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0873, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9962, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9088, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1464, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0719, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2552, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1509, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9345, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1932, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8284, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0401, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9719, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1288, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0553, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5097, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0638, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5508, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0936, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9352, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1251, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3055, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1619, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9599, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9055, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1878, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0573, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2325, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1356, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8859, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1849, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8119, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9965, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9584, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1638, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1312, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0393, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4921, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1076, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5342, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9833, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9176, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1569, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2293, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1707, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9987, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0809, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9621, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9104, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1878, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0608, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2755, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1346, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9016, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8155, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9872, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9801, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2028, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1792, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0165, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5179, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0684, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5130, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9916, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9424, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1279, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1207, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9821, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9135, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1177, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1017, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2130, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1348, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8815, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1783, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8349, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0484, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9385, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1702, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5186, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0685, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4902, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0410, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0230, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9371, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0950, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3039, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1700, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9658, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1021, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1187, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0495, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0328, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9799, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1274, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9868, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1096, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1071, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0676, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9090, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0523, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9911, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1963, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3146, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0952, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2072, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2571, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2172, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0603, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4915, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5780, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6473, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6160, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5441, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5465, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5668, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5216, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6069, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5300, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6314, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5957, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5834, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6667, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7908, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6197, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6019, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6970, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5471, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6771, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5649, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9423, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0985, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1421, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0944, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0214, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0220, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9705, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0823, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9667, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1175, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1127, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0605, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9344, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0132, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9896, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1947, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3378, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0976, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1951, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1690, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9534, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0542, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1034, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0395, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0421, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9137, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0509, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0735, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1093, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0633, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9011, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0518, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9879, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1658, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2946, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0959, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0614, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1508, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2353, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1617, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9944, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9156, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0964, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0922, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0389, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0253, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9253, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0815, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9499, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0817, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1007, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1045, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0546, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0084, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1694, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3373, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1168, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0678, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1447, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2578, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9875, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0595, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2324, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9679, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8965, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8849, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9144, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3506, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2554, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9695, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1396, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0174, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9143, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9403, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8935, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0851, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1019, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1573, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1028, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9369, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2629, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9158, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8753, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1242, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2135, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9534, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9221, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8872, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3428, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2599, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9691, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1357, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0399, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9675, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9577, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9561, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1069, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1242, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1775, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1133, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9863, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3189, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9390, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9147, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1230, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7342, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5201, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5370, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8003, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7415, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5261, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5413, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5095, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5316, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6079, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6938, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6370, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5184, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7634, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2463, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9128, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8775, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0391, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3416, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2871, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1507, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0661, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9368, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9222, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1199, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9937, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1116, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1556, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1218, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9338, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2728, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0358, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9297, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9014, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2374, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9828, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9602, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8477, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8644, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0184, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3528, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1797, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9971, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1226, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9907, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9133, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9669, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8989, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1236, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1468, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0935, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9440, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2890, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0316, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8907, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8931, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1267, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9718, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3973, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1984, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2282, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6297, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3017, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8734, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9503, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1652, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8557, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0822, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8907, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9510, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3242, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0084, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1889, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1408, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0340, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9808, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9426, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4104, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1595, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1792, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4373, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2032, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9628, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3007, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9499, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9352, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1679, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2750, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8677, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0273, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8864, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9490, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2839, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1549, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2061, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0917, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9914, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9854, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4492, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2825, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1547, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1728, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4608, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2750, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6521, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0075, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3288, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9220, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9134, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8693, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8947, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9703, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2632, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1772, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0263, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2233, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0470, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5222, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5150, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8694, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8029, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6557, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6563, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9384, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7217, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1340, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5471, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8761, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4470, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6545, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7481, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5822, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4973, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5020, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5367, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6881, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5842, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4460, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2764, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1595, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1768, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4969, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2568, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6957, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9601, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3373, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9358, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9515, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1991, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2630, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8888, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0744, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8831, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9824, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3162, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1954, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0733, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2249, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0841, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0918, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0121, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0487, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0761, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9086, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0339, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1612, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1280, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9024, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3100, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9405, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0780, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4081, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0216, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9317, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9903, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1650, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2101, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9022, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1485, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8601, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2999, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5525, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9733, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0557, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9377, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0216, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1474, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1970, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8640, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0086, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9341, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2198, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4720, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8910, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0145, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2125, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2208, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8924, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1443, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8841, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3021, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5321, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0999, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1093, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8741, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0487, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1098, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1853, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8539, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3280, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8967, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1652, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4507, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0199, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9156, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1932, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2303, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8837, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1502, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8779, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2969, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5532, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0276, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0866, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0980, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9399, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1170, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2050, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8994, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3701, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9505, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2039, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1509, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5070, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9158, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2183, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2584, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8856, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1997, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2829, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5768, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5350, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6341, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6122, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5894, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6274, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6709, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4465, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7814, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5393, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6914, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6223, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9549, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6036, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5429, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4652, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5803, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7042, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4574, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7559, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","====> Epoch: 100 Average loss: 0.0000\n","Classification Loss:  tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5107, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5465, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5071, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6695, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5477, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7562, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6328, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6797, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4118, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5344, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4977, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6958, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6569, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5467, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9148, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0296, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5838, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5201, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6397, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8206, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6446, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0840, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9982, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9029, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1460, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1507, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9266, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8250, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9714, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2206, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1331, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0442, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5139, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0572, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5435, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0949, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0085, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9310, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1213, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3059, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1561, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0567, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9591, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9044, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1904, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0464, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2308, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8877, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9982, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9584, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1642, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4923, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1042, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5380, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0538, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9851, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9123, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1539, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2210, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1623, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9931, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9646, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9083, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1874, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0503, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2728, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1336, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9001, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1870, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8102, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9789, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9830, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2029, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1715, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5213, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0671, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5257, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9417, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3279, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1173, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9838, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9036, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1185, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0980, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2076, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1408, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8768, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1758, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9366, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1732, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1503, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0518, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5138, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0741, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4847, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0327, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0236, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0873, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3041, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1687, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9637, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0955, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1168, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0089, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9779, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1173, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9796, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1013, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0561, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9124, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0476, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9922, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2010, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3081, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0902, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1136, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1962, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2564, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9891, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2138, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5612, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6295, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5995, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5264, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5294, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5510, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5150, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5954, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5136, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6124, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4898, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5877, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5118, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6503, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7730, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6172, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5938, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7120, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5269, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6677, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5413, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9421, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1015, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1398, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0896, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0135, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0437, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9685, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0766, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9656, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1117, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0611, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9367, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0210, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9910, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1905, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3418, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0752, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1947, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2306, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0287, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1627, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0537, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9457, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0518, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0945, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0186, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0394, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9075, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0501, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9247, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0758, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.1109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0689, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8930, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0586, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9789, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1688, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2960, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0968, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0634, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1506, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2362, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0122, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1516, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9989, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9102, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0977, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1224, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9823, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0380, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0280, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9238, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0832, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9478, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0726, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(2.0990, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1070, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8918, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0089, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1610, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3451, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1148, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0708, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1483, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2546, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9851, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1546, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0538, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2295, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9666, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8827, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8823, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9170, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3458, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2516, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1296, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9113, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9407, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8922, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0835, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0991, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1550, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1057, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9375, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2523, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9972, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9177, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8673, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1308, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2078, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9788, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9497, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9210, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0422, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3386, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2568, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9654, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0428, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9667, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9528, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9460, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0923, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0088, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1225, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1728, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1089, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9901, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3170, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9989, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9418, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9158, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1232, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7154, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5043, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4655, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4353, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5246, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7832, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7296, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5146, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6265, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5225, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4385, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5283, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5933, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6163, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5064, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7436, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5488, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5887, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2404, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9891, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9542, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9072, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8720, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0376, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3423, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2795, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1519, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0684, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9519, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9394, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9179, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1283, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9889, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1149, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1512, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1263, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9337, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2694, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0300, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9274, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8997, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1330, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2356, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9778, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9626, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8468, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8600, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0136, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3466, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1693, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1285, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9916, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9124, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9699, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8929, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1163, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9996, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0911, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1428, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0926, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9505, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0279, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8924, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8975, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1324, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9657, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9594, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3969, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1865, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1456, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4892, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2311, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6316, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9957, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2993, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8650, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9440, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1629, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2992, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8551, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0890, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8899, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9486, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3188, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1689, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1881, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1440, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0270, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9769, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9439, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2287, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1526, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1782, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4428, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2006, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6107, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9589, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3058, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9432, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9375, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1635, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2781, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8712, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8831, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9446, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2809, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1590, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9818, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2065, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9933, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9932, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9864, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4463, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2799, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1560, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1737, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4592, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2739, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3394, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9179, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9112, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1348, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3000, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8660, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0641, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8963, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9630, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1696, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2172, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1169, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0472, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5193, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5064, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8441, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7794, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6354, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6411, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9194, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7048, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1145, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5317, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8604, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4293, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6409, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7311, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4594, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5690, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7772, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6974, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5195, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6725, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6203, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5592, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9443, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4439, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2774, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1653, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1810, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4917, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2590, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.6941, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9575, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9275, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9510, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1954, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2544, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8901, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0687, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8820, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9798, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3140, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2008, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0737, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2204, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0853, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0882, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0190, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0430, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9085, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0268, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1601, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1232, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8998, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3055, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0139, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9393, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2264, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0839, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4109, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0806, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0250, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9388, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9869, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1616, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2060, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9072, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1399, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8582, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3017, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5585, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9697, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1023, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0520, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9399, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1460, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1994, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8639, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3261, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9292, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2209, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1570, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4628, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0748, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8839, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2056, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2273, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8818, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1291, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8806, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2932, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5301, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9841, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1070, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8698, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1862, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8484, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3193, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8894, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1633, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1452, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.4455, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1034, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0247, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9166, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1867, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2303, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8788, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1529, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8762, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3020, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5551, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0962, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9374, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0701, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1200, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2122, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8987, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.3746, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9809, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9546, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2028, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.1496, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5076, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0853, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.0091, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9074, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9978, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2212, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2621, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.8838, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2047, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9021, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.2773, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(1.5816, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5136, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6240, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6051, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5701, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6090, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6493, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4385, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7558, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5204, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4661, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6765, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6049, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9345, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5881, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5206, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.5663, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6902, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7216, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4491, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.6473, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.4398, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.7445, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n","Classification Loss:  tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>) MSE Loss:  tensor(0.9704, device='cuda:0', grad_fn=<MseLossBackward0>)\n","MMD Loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n","====> Epoch: 100 Average loss: 0.0000\n","MODEL SAVED\n","TRAIN LOSS: [3.5949850082397464e-05, 3.4166460037231444e-05, 3.325196743011475e-05, 3.2570087909698484e-05, 3.1897151470184326e-05, 3.121479272842407e-05, 3.054356336593628e-05, 2.9834890365600586e-05, 2.9061603546142576e-05, 2.823629379272461e-05, 2.7288808822631836e-05, 2.635946035385132e-05, 2.5414578914642333e-05, 2.4403412342071532e-05, 2.3291363716125487e-05, 2.203780174255371e-05, 2.0806005001068116e-05, 1.970320224761963e-05, 1.8601863384246828e-05, 1.7628363370895386e-05, 1.669767141342163e-05, 1.5881175994873046e-05, 1.5130101442337036e-05, 1.4417294263839721e-05, 1.378140926361084e-05, 1.3205454349517822e-05, 1.2699507474899291e-05, 1.2271052598953247e-05, 1.1943917274475098e-05, 1.168226718902588e-05, 1.145369052886963e-05, 1.1248255968093871e-05, 1.1049973964691162e-05, 1.0891388654708863e-05, 1.0761566162109374e-05, 1.0638561248779298e-05, 1.0526005029678345e-05, 1.042338728904724e-05, 1.033618688583374e-05, 1.0241605043411254e-05, 1.0132203102111817e-05, 1.0016601085662842e-05, 9.909359216690064e-06, 9.815906286239624e-06, 9.715914726257324e-06, 9.6393221616745e-06, 9.647729992866517e-06, 9.525012373924255e-06, 9.364190101623535e-06, 9.336560368537903e-06, 9.163264632225037e-06, 9.182508587837219e-06, 9.075152277946472e-06, 8.970828056335449e-06, 8.966411948204041e-06, 8.81773591041565e-06, 8.804532885551453e-06, 8.772509694099427e-06, 8.660771250724792e-06, 8.630406260490417e-06, 8.57621729373932e-06, 8.479353189468384e-06, 8.47647249698639e-06, 8.42250645160675e-06, 8.348820209503174e-06, 8.317468762397766e-06, 8.293894529342651e-06, 8.227238059043884e-06, 8.157756924629212e-06, 8.128662109375e-06, 8.125221729278565e-06, 8.11520755290985e-06, 8.09313178062439e-06, 7.97231912612915e-06, 7.96566069126129e-06, 8.057041764259339e-06, 8.047009706497192e-06, 7.90308177471161e-06, 7.95468032360077e-06, 7.779667973518372e-06, 7.854708433151244e-06, 8.016414642333985e-06, 7.840267419815063e-06, 7.88630247116089e-06, 7.774255871772767e-06, 7.779694199562073e-06, 7.66777217388153e-06, 7.628161907196045e-06, 7.63224482536316e-06, 7.526370882987976e-06, 7.570273280143738e-06, 7.4531173706054684e-06, 7.524171471595764e-06, 7.50162661075592e-06, 7.385056614875793e-06, 7.412266731262207e-06, 7.339881658554077e-06, 7.331059575080872e-06, 7.331951260566712e-06, 7.179061770439148e-06]\n","PLOTTING TRAINING:\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["try:\n","    train_AE()\n","    PATH = \"/content/gdrive/Shareddrives/Anomaly/weights/meta_latent_model_MI_V4.pth\"\n","    torch.save(multitaskAE.state_dict(), PATH)\n","    print(\"MODEL SAVED\")\n","    print (\"TRAIN LOSS:\", train_losses)\n","    print(\"PLOTTING TRAINING:\")\n","    X = np.arange(epochs)\n","    Y = train_losses\n","    plt.plot(X, Y)\n","    plt.savefig('loss_vs_epoch.png')\n","\n","except KeyboardInterrupt:\n","    # save model\n","    PATH = \"/content/gdrive/Shareddrives/Anomaly/weights/meta_latent_model_MI_V4.pth\"\n","    torch.save(multitaskAE.state_dict(), PATH)\n","    print(\"MODEL SAVED\")\n","    print(\"PLOTTING TRAINING:\")\n","    X = np.arange(epochs)\n","    Y = train_losses\n","    plt.plot(X, Y)\n","    plt.savefig('loss_vs_epoch.png')"]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","class DataBuilder(Dataset):\n","    def __init__(self, X_test, y_test):\n","        #self.x, self.standardizer, self.wine = load_data(DATA_PATH)\n","        self.x, self.y = X_test, y_test\n","        self.len=self.x.shape[0]\n","    def __getitem__(self,index):\n","        return self.x[index], self.y[index]\n","    def __len__(self):\n","        return self.len"],"metadata":{"id":"J4iPM5WP8b3D","executionInfo":{"status":"ok","timestamp":1696187956897,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AgNXur4y9xiI","executionInfo":{"status":"ok","timestamp":1696187956897,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n","\n","def test(X_test, y_test):\n","  data_set=DataBuilder(X_test, y_test)\n","  testloader=DataLoader(dataset=data_set,batch_size=1)\n","  correct = 0\n","  total = 0\n","  predict_lst = []\n","  labels_lst = []\n","\n","  # since we're not training, we don't need to calculate the gradients for our outputs\n","  with torch.no_grad():\n","      multitaskAE.eval()\n","      for data in testloader:\n","          X_test, labels = data\n","          X_test = X_test.float().to(device)\n","          labels = labels.long().to(device)\n","          # calculate outputs by running images through the network\n","          logits, recon_batch, Z = multitaskAE(X_test)\n","          #print (\"logits:\", logits)\n","\n","          # the class with the highest energy is what we choose as prediction\n","          _, predicted = torch.max(logits.data, 1)\n","          predict_lst.append(predicted.cpu().detach().numpy())\n","          #predicted = torch.argmax(logits)\n","\n","          labels_lst.append(labels[0].cpu().detach().numpy())\n","\n","          #print(\"out:\", _)\n","\n","          #print (\"PREDICTED:\", predicted)\n","\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  print(f'Accuracy of the network on the test images: {100 * correct / total} %')\n","\n","  prec = precision_score(labels_lst, predict_lst)\n","  rec = recall_score(labels_lst, predict_lst)\n","  f1 = f1_score(labels_lst, predict_lst)\n","  roc_auc = roc_auc_score(labels_lst, predict_lst)\n","  print(prec, rec, f1, roc_auc)"],"metadata":{"id":"yjM__reS918R","executionInfo":{"status":"ok","timestamp":1696187957065,"user_tz":240,"elapsed":171,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rxAnAQ6p8Dnz","executionInfo":{"status":"ok","timestamp":1696187957065,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["test(np.concatenate((X_BOT_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_BOT_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"omhf-4eKWNzq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696187981707,"user_tz":240,"elapsed":24646,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"7bbb7012-2774-41c2-c173-35a595655d21"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 48.16003208663391 %\n","0.0029239766081871343 0.0001 0.0001933861922258751 0.48290743012266235\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_RARE_test[:566], X_BENIGN_TEST_test[:566])), np.concatenate((y_RARE_test[:566], y_BENIGN_TEST_test[:566])))"],"metadata":{"id":"CJEZhx9SZU1r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696187983021,"user_tz":240,"elapsed":1322,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"0e4ea5ab-b2a1-43fc-ad3a-b112d029be94"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 51.32508833922262 %\n","0.6229508196721312 0.06713780918727916 0.12121212121212122 0.5132508833922261\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_SlowHTTPTest_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_SlowHTTPTest_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"3seX0NBmZVCB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696188007504,"user_tz":240,"elapsed":24486,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"388213c5-f5bc-4132-afb5-19ae8cf4b374"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 48.18509976937732 %\n","0.01729106628242075 0.0006 0.0011597564511452595 0.4831574301226623\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_OOD_INFIL_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_OOD_INFIL_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"m9iZTEvzZVE0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696188032102,"user_tz":240,"elapsed":24602,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"de00af71-487a-4f87-a5a4-facd527c7103"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 48.63631805875865 %\n","0.21967963386727687 0.0096 0.018396090830698476 0.4876574301226624\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_DDOS_SOLARIS_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_DDOS_SOLARIS_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"t20E2uC4aBLx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696188056742,"user_tz":240,"elapsed":24645,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"8c55059c-14cf-4da2-c44d-7f9382eacc2a"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 59.83655870851298 %\n","0.8723324597529015 0.233 0.36776892115855103 0.5993574301226624\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_DDOS_HOIC_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_DDOS_HOIC_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"lY_2TVR7aBRn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696188081165,"user_tz":240,"elapsed":24428,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"2789f8b8-06ce-484b-cd1d-6002ba425b51"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 72.09465557003911 %\n","0.9333463643471462 0.4775 0.6317808944165122 0.7216074301226624\n"]}]},{"cell_type":"code","source":["test(np.concatenate((X_DDOS_GOLDEN_EYE_test[:10000], X_BENIGN_TEST_test[:10000])), np.concatenate((y_DDOS_GOLDEN_EYE_test[:10000], y_BENIGN_TEST_test[:10000])))"],"metadata":{"id":"8P5ULiRlaTQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696188105402,"user_tz":240,"elapsed":24241,"user":{"displayName":"Himanshu Singhal","userId":"01652204392388706177"}},"outputId":"e2e8c851-b8f1-49ec-c944-dd28eac76e01"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 54.828035696380226 %\n","0.7960526315789473 0.1331 0.228067169294037 0.5494074301226624\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}