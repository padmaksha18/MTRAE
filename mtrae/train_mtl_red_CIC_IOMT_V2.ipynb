{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "BiC-pZ_7p7an",
        "outputId": "ad4cb226-5f65-4d3a-d20a-ed2760f8fd0a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2062cacb8d7a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#drive.flush_and_unmount()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTKNOgjyNrlS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZKp_qT5sF1d",
        "outputId": "b1052294-40b6-41e6-d5b8-e16f8f4934c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/MTL-RED\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/MTL-RED/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBeEpLI5p_lF",
        "outputId": "e3e81c8d-a3be-472c-e34e-947fe583592d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 395\n",
            "-rw------- 1 root root   1197 Nov 28  2023 data_preprocess_mtl_red_cic_ids_10.py\n",
            "-rw------- 1 root root   9821 Nov 28  2023 multitaskAutoencoders_mtl_red_cic_ids_10.py\n",
            "drwx------ 2 root root   4096 Feb 13  2024 DATA\n",
            "drwx------ 2 root root   4096 Mar  1 05:43 MODELS\n",
            "drwx------ 2 root root   4096 Mar  1 18:40 __pycache__\n",
            "drwx------ 2 root root   4096 Mar  5 19:58 RESULTS\n",
            "-rw------- 1 root root   1356 Mar  7 19:36 data_preprocess_3.py\n",
            "-rw------- 1 root root   9543 Mar  8 21:57 MTL_RED_CIC_IOT_3.py\n",
            "drwx------ 2 root root   4096 Mar  9 23:05 BASELINES\n",
            "-rw------- 1 root root   1388 Mar 16 21:51 data_preprocess_CIC_IOT_50.py\n",
            "-rw------- 1 root root   9564 Mar 17 20:48 MTL_RED_CIC_IOT_50.py\n",
            "-rw------- 1 root root   1354 Mar 18 00:00 data_preprocess_cic_ids.py\n",
            "-rw------- 1 root root   1334 Mar 18 00:09 data_preprocess_cic_iomt.py\n",
            "-rw------- 1 root root   9537 Mar 19 20:59 MTL_RED_IOMT_50.py\n",
            "-rw------- 1 root root   9545 Mar 20 19:20 MTL_RED_CIC_IDS.py\n",
            "-rw------- 1 root root   9536 Mar 20 22:22 MTL_RED_IOMT_30.py\n",
            "-rw------- 1 root root 317415 Mar 21 01:36 MTL_RED_CIC_IDS.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls -lrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSmlpT7mp_qA"
      },
      "outputs": [],
      "source": [
        "#!python /content/gdrive/MyDrive/OOD_generalization/mate-mi-reg-model/multitaskAutoencoders.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k29kXCUrEInI"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dYXKKEWRPbg"
      },
      "source": [
        "**BATCH = 50, DATA = 10K**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "251JjqlT14jS",
        "outputId": "2439604f-98a0-4db6-e1ab-893dcff12782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAPE TRAIN DATA: (24477, 20)\n",
            "Ytrain shape: (24477,)\n",
            "D_in shape: 20\n"
          ]
        }
      ],
      "source": [
        "from MTL_RED_IOMT_30 import MultitaskAutoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nobgCYMZ-7bS"
      },
      "source": [
        "**TESTING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMIiBpCl6PGL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMEIA5dxgL5I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T6x-rg4fIT4"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "\n",
        "    #train_data = pd.read_csv(path, sep=',')\n",
        "    #train_data = train_data.sample(frac = 1).reset_index(drop=True)\n",
        "    train_data = path\n",
        "    train_data[train_data.select_dtypes(np.float64).columns] = train_data.select_dtypes(np.float64).astype(np.float32)\n",
        "\n",
        "    x_train = train_data.loc[:,train_data.columns != 'Label']\n",
        "\n",
        "    x_train = torch.tensor(x_train.values)\n",
        "    #x_train = x_train.values.astype['float32']\n",
        "\n",
        "    y_train = train_data.loc[:,train_data.columns == 'Label']\n",
        "    y_train = torch.tensor(y_train.values)\n",
        "    y_train = y_train.long()\n",
        "\n",
        "    print (\"X train shape:\", x_train.shape)\n",
        "    print (\"Y train shape:\", y_train.shape)\n",
        "\n",
        "    return x_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77mvGWmfEIq5"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class DataBuilder(Dataset):\n",
        "    def __init__(self, path):\n",
        "        #self.x, self.standardizer, self.wine = load_data(DATA_PATH)\n",
        "        self.x, self.y = load_data(path)\n",
        "        self.len=self.x.shape[0]\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hf8zZj8WE4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_recon = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CSE_CIC_IDS/TRAIN/TEST_INFIL.csv\")#CROSS_DOM_MQTT.csv\") #TEST_OOD_RECON.csv\") #TEST_OOD_SPOOFING.csv\")\n",
        "data_benign = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CSE_CIC_IDS/BENIGN_TEST.csv\")\n",
        "\n",
        "\n",
        "data_recon = data_recon.loc[data_recon['Label'] == 1]\n",
        "#data_recon = data_recon.sample(n=10000, replace= True)\n",
        "\n",
        "data_benign = data_benign.loc[data_benign['Label'] == 0]\n",
        "\n",
        "data_benign = data_benign[0:5000]\n",
        "data_recon = data_recon[0:5000]\n",
        "\n",
        "data_test = pd.concat([data_recon, data_benign])\n",
        "data_test = data_test.sample(frac = 1).reset_index(drop=True)\n",
        "\n",
        "#data_bot = data_bot.loc[data_bot['Label'] == 1]\n",
        "DATA_PATH = data_test[0:10000]\n",
        "DATA_PATH"
      ],
      "metadata": {
        "id": "k5I32wz4dOKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_set=DataBuilder(DATA_PATH)\n",
        "# testloader=DataLoader(dataset=data_set,batch_size=10000)\n",
        "\n",
        "D_in = 29\n",
        "print (\"D_in shape:\", D_in)\n",
        "H = 25\n",
        "H2 = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEMMGrDyeAGt",
        "outputId": "6b1e4513-5e0a-4e89-cf42-9edc9e6515c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D_in shape: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xe_FAoek9kMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PATH = \"/content/gdrive/MyDrive/MTL-RED/MODELS/MODELS_CIC_IOMT_DOS_DDOS_SPOOF_RECON/50_PERCENT/_multi_domain_MI_2_REC_06_2_2.pth\"\n",
        "\n",
        "#PATH = \"/content/gdrive/MyDrive/MTL-RED/MODELS/MTAE/CIC_IOMT_TRAIN_FINAL_DOS_DDOS_SPOOF_RECON_30_PERCENT.pth\"\n",
        "\n",
        "\n",
        "PATH = \"/content/gdrive/MyDrive/MTL-RED/MODELS/CIC_CSE_IDS/multi_domain_MI_2_REC_06_0.05_0.27.pth\"\n",
        "\n",
        "#PATH = \"/content/gdrive/MyDrive/MTL-RED/MODELS/MTAE/CSE_CIC_IDS/CIC_CSE_IDS_TRAIN_IN_SOLARIS_GOLDEN_BOT_INFIL.pth\""
      ],
      "metadata": {
        "id": "Sqi2wu7YdONH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = MultitaskAutoencoder(D_in, H, H2)#.to(device)\n",
        "#map_location=torch.device('cpu')\n",
        "#model_test.load_state_dict(torch.load(PATH))\n",
        "torch.load(PATH, map_location=torch.device('cpu'), weights_only=True)"
      ],
      "metadata": {
        "id": "nM6dnCBodOPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lk1PpWFzgETU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_data = np.random.randn(1000, 3)  # Example of 1000 normal 3-dimensional points\n",
        "anomaly_data = np.random.randn(100, 3)"
      ],
      "metadata": {
        "id": "pb9CtFcqc1eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (normal_data.shape)\n",
        "print (anomaly_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFTENE4rc1iS",
        "outputId": "9975cd17-f4e6-4b8e-804d-a836aaeefb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3)\n",
            "(100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xo22a35yc1mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkidkcC_3Kxd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww5CTBYKuHKx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLpPjMf7uNcO",
        "outputId": "db166a60-7fba-462b-a51c-07671257aede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D_in shape: 26\n"
          ]
        }
      ],
      "source": [
        "D_in = 26\n",
        "print (\"D_in shape:\", D_in)\n",
        "H = 20\n",
        "H2 = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ycn8zzGKEjf"
      },
      "source": [
        "**TEST MULTIPLE DATASETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp3aslUMBTog"
      },
      "outputs": [],
      "source": [
        "DATA_PATHS = [\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_RECON.csv\",\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/CROSS_DOM_MQTT.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_SPOOFING.csv\", \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_DOS.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_DDOS.csv\", \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_BENIGN.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_BENIGN.csv\"\n",
        "              ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATHS = [\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_IN_BENIGN.csv\",\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_DOS.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_DDOS.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_BRUTFORCE.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_MIRAI.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_RECON.csv\", \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_SPOOF.csv\",\n",
        "              \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_WEB.csv\", \"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_BENIGN.csv\"\n",
        "              ]"
      ],
      "metadata": {
        "id": "35EBulC3Wm-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnT2bREwXuqt"
      },
      "outputs": [],
      "source": [
        "data_train_recon_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_RECON.csv\")\n",
        "data_train_mqtt_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/CROSS_DOM_MQTT.csv\")\n",
        "data_train_spoofing_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_SPOOFING.csv\")\n",
        "data_train_dos_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_DOS.csv\")\n",
        "data_train_ddos_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_DDOS.csv\")\n",
        "train_in_benign_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TRAIN_IN_BENIGN.csv\")\n",
        "train_ood_benign_iomt = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOMT/TEST_OOD_BENIGN.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train_ddos_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_DDOS.csv\")\n",
        "data_train_dos_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_DOS.csv\")\n",
        "data_train_brut_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_BRUTFORCE.csv\")\n",
        "data_train_mirai_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_MIRAI.csv\")\n",
        "data_train_recon_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_RECON.csv\")\n",
        "train_ood_spoof_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_SPOOF.csv\")\n",
        "train_ood_web_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_OOD_WEB.csv\")\n",
        "train_in_benign_iot = pd.read_csv(\"/content/gdrive/MyDrive/MTL-RED/DATA/CIC_IOT_MULTICLASS/TEST_IN_BENIGN.csv\")\n"
      ],
      "metadata": {
        "id": "DLUEb54pXBXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_ddos_iot = data_train_ddos_iot.rename(columns={\"label\": 'Label'})\n",
        "data_train_dos_iot = data_train_dos_iot.rename(columns={\"label\": 'Label'})\n",
        "data_train_brut_iot = data_train_brut_iot.rename(columns={\"label\": 'Label'})\n",
        "data_train_mirai_iot = data_train_mirai_iot.rename(columns={\"label\": 'Label'})\n",
        "data_train_recon_iot = data_train_recon_iot.rename(columns={\"label\": 'Label'})\n",
        "train_ood_web_iot= train_ood_web_iot.rename(columns={\"label\": 'Label'})\n",
        "train_in_benign_iot = train_in_benign_iot.rename(columns={\"label\": 'Label'})"
      ],
      "metadata": {
        "id": "-loC34cPagQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"Header_Length\", \"Duration\", \"Rate\", \"rst_count\",  \"ack_count\", \"syn_count\",\n",
        "               \"fin_count\", 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number',\n",
        "       'Magnitue', 'Radius', 'Covariance', 'Variance', 'Weight', 'Label' ]\n",
        "\n",
        "\n",
        "# # Replace values in the 'Department' colum\n",
        "#data_train_mirai"
      ],
      "metadata": {
        "id": "2Tc9FGmlaSJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_recon_iomt = data_train_recon_iomt[cols]\n",
        "data_train_mqtt_iomt = data_train_mqtt_iomt[cols]\n",
        "data_train_spoofing_iomt = data_train_spoofing_iomt[cols]\n",
        "data_train_dos_iomt = data_train_dos_iomt[cols]\n",
        "data_train_ddos_iomt = data_train_ddos_iomt[cols]\n",
        "train_in_benign_iomt = train_in_benign_iomt[cols]\n",
        "train_ood_benign_iomt = train_ood_benign_iomt[cols]\n",
        "\n",
        "\n",
        "data_train_ddos_iot = data_train_ddos_iot[cols]\n",
        "data_train_dos_iot = data_train_dos_iot[cols]\n",
        "data_train_brut_iot = data_train_brut_iot[cols]\n",
        "data_train_mirai_iot = data_train_mirai_iot[cols]\n",
        "data_train_recon_iot = data_train_recon_iot[cols]\n",
        "train_ood_web_iot = train_ood_web_iot[cols]\n",
        "train_in_benign_iot = train_in_benign_iot[cols]\n"
      ],
      "metadata": {
        "id": "0tQ-MC5zaQAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATHS = ['']"
      ],
      "metadata": {
        "id": "p7wVmDGIdAtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87Y--NMKvLaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WDMGEk9nvVks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn16QZQqW0Mm",
        "outputId": "d811ed5e-8e56-4067-a1c7-9a060f159e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/MTL-RED/MODELS/CIC_IOMT/30_PERCENT_SPOOF\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/MTL-RED/MODELS/CIC_IOMT/30_PERCENT_SPOOF/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma2hMqF-xKEm"
      },
      "outputs": [],
      "source": [
        "!ls -lrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmi48jg4vwF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "fcdad908-f224-4b18-a1f9-4319aa0cc672",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_multi_domain_MI_2_REC_06_2.0_2.0.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for MultitaskAutoencoder:\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([13, 20]) from checkpoint, the shape in current model is torch.Size([15, 20]).\n\tsize mismatch for linear2.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear3.weight: copying a param with shape torch.Size([13, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for linear3.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([15, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([13, 15]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear4.weight: copying a param with shape torch.Size([13, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for linear4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear5.weight: copying a param with shape torch.Size([20, 13]) from checkpoint, the shape in current model is torch.Size([20, 15]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-39fa06e55455>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultitaskAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2154\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultitaskAutoencoder:\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([13, 20]) from checkpoint, the shape in current model is torch.Size([15, 20]).\n\tsize mismatch for linear2.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn2.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear3.weight: copying a param with shape torch.Size([13, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for linear3.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn3.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([15, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([13, 15]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear4.weight: copying a param with shape torch.Size([13, 13]) from checkpoint, the shape in current model is torch.Size([15, 15]).\n\tsize mismatch for linear4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.weight: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.running_mean: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for lin_bn4.running_var: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([15]).\n\tsize mismatch for linear5.weight: copying a param with shape torch.Size([20, 13]) from checkpoint, the shape in current model is torch.Size([20, 15])."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "directory_path = '/content/gdrive/MyDrive/MTL-RED/MODELS/CIC_IOMT/30_PERCENT_SPOOF/'\n",
        "\n",
        "# Use glob to get a list of all CSV files in the directory\n",
        "model_files = glob.glob(os.path.join(directory_path, '_multi_domain_MI_2_REC_06_2.0_2.0.pth'))\n",
        "\n",
        "for model in model_files:\n",
        "  model = model.split(\"/\")[-1]\n",
        "  print (model)\n",
        "\n",
        "  model_test = MultitaskAutoencoder(D_in, H, H2)#.to(device)\n",
        "  map_location=torch.device('cpu')\n",
        "  model_test.load_state_dict(torch.load(model)) # Load model\n",
        "  model_test.eval()\n",
        "\n",
        "  accuracies = []\n",
        "\n",
        "  for data in DATA_PATHS:\n",
        "    #print (data)\n",
        "    data_set=DataBuilder(data)\n",
        "    testloader=DataLoader(dataset=data_set,batch_size=1)\n",
        "\n",
        "    predict_lst = []\n",
        "    labels_lst = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data in testloader:\n",
        "        X_test, labels = data\n",
        "\n",
        "        # calculate outputs by running images through the network\n",
        "        logits, recon_batch, Z = model_test(X_test)#.to(device)\n",
        "        #print (\"logits:\", logits)\n",
        "\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        predict_lst.append(predicted.cpu().detach().numpy())\n",
        "        #predicted = torch.argmax(logits)\n",
        "\n",
        "        labels_lst.append(labels[0].cpu().detach().numpy())\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "      accuracy = 100 * correct / total\n",
        "      #print (accuracy)\n",
        "\n",
        "      accuracies.append(accuracy)\n",
        "      #print (accuracies)\n",
        "\n",
        "  row_data = {'RECON_IOMT': accuracies[0],'MQTT': accuracies[1],'SPOOF_IOMT': accuracies[2],'DOS_IOMT': accuracies[3], 'DDOS_IOMT': accuracies[4],\n",
        "                  'BENIGN_IOMT': accuracies[5], 'OOD-BENIGN_IOMT': accuracies[6], 'DDOS_IOT': accuracies[7], 'DOS_IOT': accuracies[8],\n",
        "              'BRUT_IOT': accuracies[9], 'MIRAI_IOT': accuracies[10], 'RECON_IOT': accuracies[11], 'WEB_IOT': accuracies[12], 'BENIGN_IOT': accuracies[13] }\n",
        "\n",
        "  #print (\"ROW DATA:\", row_data)\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  df_new = pd.DataFrame([row_data])\n",
        "\n",
        "  # Concatenate the original DataFrame with the new row DataFrame\n",
        "  df = pd.concat([df, df_new], ignore_index=True)\n",
        "\n",
        "  filename = f\"file_{model}\"\n",
        "\n",
        "  df.to_csv(\"/content/gdrive/MyDrive/MTL-RED/RESULTS/CIC_IOMT/ALL_CLASSES_IOT_IOMT_2/results_{0}.csv\".format(filename), index = False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd7WWBshCgUm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBkEubvpCgaL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}